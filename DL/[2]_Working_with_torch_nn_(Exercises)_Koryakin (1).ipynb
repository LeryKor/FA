{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH5oeW6ZgWG6"
      },
      "source": [
        "## Создание архитектуры нейронной сети посредством модуля torch.nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQBSvxKjgWG-"
      },
      "source": [
        "Нейронные сети состоят из слоев, которые производят преобразования над данными. В PyTorch принято называть слои ***модулями*** (modules), и далее мы тоже будем использовать это название.\n",
        "\n",
        "Для большей чёткости в структуре нейронной сети используются классы. В PyTorch есть отдельный класс [torch.nn](https://pytorch.org/docs/stable/nn.html), специально созданный для работы с нейронными сетями. В нём уже реализованы все типы слоёв и функций активации. Это позволяет существенно сократить код и упростить работу с нейронными сетями.\n",
        "\n",
        "Пространство имен [`torch.nn`](https://pytorch.org/docs/stable/nn.html) предоставляет \"строительные блоки\", которые нужны для создания своей собственной нейронной сети. Каждый *модуль* в PyTorch является дочерним классом от [`nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html). Таким образом, нейронная сеть сама по себе будет являться *модулем*, состоящим из других *модулей* (слоев). Такая вложенная структура позволяет легко создавать сложные архитектуры и управлять ими.\n",
        "\n",
        "Сначала импортируем модуль (from torch import nn) и потом обращаемся к нему:\n",
        "функция активации ReLU --- nn.ReLU();\n",
        "функция активации sigmoid --- nn.Sigmoid();\n",
        "линейный слой --- nn.Linear();\n",
        "свёрточный слой --- nn.Conv2d() и т.д.\n",
        "\n",
        "Рассмотрим основные \"строительные блоки\", при помощи которых мы будем создавать нейронные сети."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXBFP8ZhgWG_"
      },
      "source": [
        "# Подмодуль torch.nn.Module --- описание класса модели\n",
        "\n",
        "Мы определяем нейронную сеть, наследуясь от класса `nn.Module`, и инициализируем ее слои в методе `__init__`. Каждый класс-наследник `nn.Module` производит операции над входными данными в методе `forward`.\n",
        "\n",
        "Множество слоев в нейронных сетях имеют *обучаемые параметры*, т. е. имеют ассоциированные с ними веса и смещения, которые оптимизируются во время обучения.\n",
        "\n",
        "Наследование от `nn.Module` автоматически отслеживает все слои, определенные внутри вашего класса модели, и делает все их параметры доступными с помощью методов `model.parameters()` или `model.named_parameters()`.\n",
        "\n",
        "Создадим на базе класса `nn.Module` свой собственный класс, который будет его наследником. В качестве объекта возьмём нейронную сеть из предыдущего раздела:\n",
        "\n",
        "<img src='assets/multilayer_diagram_weights.png' width=\"1000\">\n",
        "\n",
        "Эта простая нейронная сеть состоит из двух линейных слоёв: первый размером $3 \\times 2$ с последующим применением функции активации ReLU, второй размером $2 \\times 1$. Обращаю внимание на метод forward() --- именно он отвечает за \"проход по нейронной сети\". Строгое определение: процесс передачи значений от входных нейронов к выходным называется прямым распространением (forward pass)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lJcL1jGgWHA"
      },
      "source": [
        "Сначала подключим необходимые библиотеки:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bJITcq6gWHB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49YUFiJLgWHC"
      },
      "source": [
        "Потом создадим класс через наследование от класса `nn.Module`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BX6MrEa6gWHC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.hidden = nn.Linear(3, 2)\n",
        "\n",
        "        self.output = nn.Linear(2, 1)\n",
        "\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.hidden(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.output(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfdU1TgbgWHD"
      },
      "source": [
        "Чтобы использовать модель, необходимо передать ей входные данные. Это приводит в действие метод `forward`, а также определенные фоновые операции. Не следует вызывать `model.forward` напрямую!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_xNnluAgWHD"
      },
      "source": [
        "Создадим случайный входной вектор размерности $1 \\times 3$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfJy4CmIgWHD",
        "outputId": "16cb316e-0fc9-4ea8-8522-e7a41d8961f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": "tensor([[-0.9111, -1.0646, -0.3326]])"
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input = torch.randn(1, 3)\n",
        "input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzIsstdbgWHE"
      },
      "source": [
        "Чтобы начать работу с построенной нейронной сетью, необходимо сначала создать экземпляр описанного класса Network()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKLD2M66gWHF"
      },
      "outputs": [],
      "source": [
        "model = Network()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RfgIxw2gWHF"
      },
      "source": [
        "При обращении к этому классу получим описание структуры созданной нейронной сети."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlvgZRoUgWHF",
        "outputId": "9ac6dc7a-b558-4938-83cc-c4a522947686"
      },
      "outputs": [
        {
          "data": {
            "text/plain": "Network(\n  (hidden): Linear(in_features=3, out_features=2, bias=True)\n  (output): Linear(in_features=2, out_features=1, bias=True)\n  (activation): ReLU()\n)"
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56BdVo1lgWHG"
      },
      "source": [
        "Теперь \"пропустим\" через полученную нейронную сеть созданный нами входной вектор input, выведем на экран полученный результат и его размерность:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNwEuYEXgWHG",
        "outputId": "1bf6d7c9-6149-4a3f-b2d6-1ceff344df67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.2910]], grad_fn=<AddmmBackward0>)\n",
            "torch.Size([1, 1])\n"
          ]
        }
      ],
      "source": [
        "result = model(input)\n",
        "print(result)\n",
        "print(result.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HN2Za0KagWHG"
      },
      "source": [
        "Поскольку выходное множество состоит из одного элемента, извлечём его явное значение:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xV4U1nvQgWHG",
        "outputId": "89ade7e0-abc0-4e31-cf06-40a1a5850b19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": "0.290996253490448"
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "value = result.item()\n",
        "value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qL5dE5UgWHH"
      },
      "source": [
        "# Подмодули для функций активации\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/neurons_output.png\" width=\"1000\">\n",
        "\n",
        "Функции активации должны обладать следующими свойствами:\n",
        "\n",
        "* **Нелинейность:** функция активации необходима для введения нелинейности в нейронные сети. Если функция активации не применяется, выходной сигнал становится простой линейной функцией. Нейронная сеть без нелинейностей будет действовать как линейная модель с ограниченной способностью к обучению:\n",
        "$$\\hat{y}=NN(X,W_1,...,W_n)=X\\cdot W_1\\cdot ...\\cdot W_n=X\\cdot W$$\n",
        "Только нелинейные функции активации позволяют нейронным сетям решать задачи аппроксимации нелинейных функций:\n",
        "$$\\hat{y}=NN(X,W_1,...,W_n)=\\sigma(...\\sigma(X\\cdot W_1)...\\cdot W_n)\\neq X\\cdot W$$\n",
        "\n",
        "* **Дифференцируемость:** функции активации должны быть способными пропускать градиент, чтобы было возможно оптимизировать параметры сети градиентными методами, в частности использовать алгоритм обратного распространения ошибки.\n",
        "\n",
        "\n",
        "Любая функция активации задаётся просто своим названием: nn.ReLU, nn.Tanh, nn.Sigmoid."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvxHu4BPgWHH"
      },
      "source": [
        "## Подмодуль для линейного слоя nn.Linear\n",
        "\n",
        "Линейный слой [`nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) — это модуль, который производит линейное преобразование входных данных с помощью хранящихся в нем весов и смещений.\n",
        "\n",
        "Обязательными параметрами при объявлении этого слоя являются `in_features` — количество входных признаков, и `out_features` — количество выходных признаков.\n",
        "\n",
        "Фактически, этот модуль добавляет в модель один полносвязный слой нейронов *без активаций*. Слой состоит из `out_features` нейронов, каждый из которых имеет `in_features` входов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypI4I7p5gWHI"
      },
      "source": [
        "## Подмодуль для объединения слоёв в одну последовательность nn.Sequential\n",
        "\n",
        "[`nn.Sequential`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) — это упорядоченный контейнер для модулей. Данные проходят через все модули в том же порядке, в котором они определены в `nn.Sequential`. Можно использовать такой контейнер для того, чтобы быстро собрать простую нейронную сеть, что мы и сделаем."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8-9zqF9gWHI"
      },
      "source": [
        "## Подмодуль nn.Flatten\n",
        "\n",
        "Мы используем слой nn.Flatten для преобразования каждого изображения 1×28×28 пикселей в непрерывный массив из 784 значений (размер батча (на позиции dim=0) сохраняется)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAvhov3ngWHI"
      },
      "source": [
        "## Подмодуль для результирующего слоя nn.Softmax\n",
        "\n",
        "Последний линейный слой нейронной сети возвращает *логиты* — \"сырые\" значения из диапазона $[-∞; +∞]$, которые могут быть пропущены через модуль [`nn.Softmax`](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html). Пропущенные через $\\text{sofmax}$ величины могут восприниматься как вероятности, с которыми модель относит данный объект к тому или иному классу. Параметр `dim` определяет размерность, вдоль которой величины должны суммироваться к $1$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4r9L_F6gWHI"
      },
      "source": [
        "## Пример применения всех описанных подмодулей\n",
        "\n",
        "Для иллюстрации возьмем мини-батч (в данном случае представленный тензором, заполненным случайными числами) из трех одноканальных изображений $28 \\times 28$ и посмотрим, что с ним происходит, когда мы пропускаем его через сеть.\n",
        "Обращаю внимание, что изображения хранятся в разных форматах, здесь будем использовать размерность (batch_size, channels, height, width).\n",
        "Итак, создаём тензор указанной размерности и выводим его размер."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LCGT_ltgWHJ",
        "outputId": "be92000b-8738-41cd-f811-21a5d7dd2cb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input size: torch.Size([3, 1, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "sample_batch = torch.randn(3, 1, 28, 28)\n",
        "print(f\"Input size: {sample_batch.size()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mzfGeyKgWHJ"
      },
      "source": [
        "Вытянем наши тестовые изображения в один вектор и выведем его размер."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMx0lCAEgWHJ",
        "outputId": "2890beb7-1efc-44a0-a66f-c7cf30ac24a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size after Flatten: torch.Size([3, 784])\n"
          ]
        }
      ],
      "source": [
        "flatten = nn.Flatten()\n",
        "flat_image = flatten(sample_batch)\n",
        "print(f\"Size after Flatten: {flat_image.size()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nu1Jz05UgWHK"
      },
      "source": [
        "Далее объявим линейный слой из 512 нейронов, каждый из которых получает \"вытянутое\" изображение из 784 пикселей. Пропустим через него это изображение и выведем на экран его размерность."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4h5vrQ5gWHK",
        "outputId": "9316a3cb-c1e4-4a1a-85b1-629a5b3cb10c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size after Linear: torch.Size([3, 512])\n"
          ]
        }
      ],
      "source": [
        "layer1 = nn.Linear(784, 512)\n",
        "hidden1 = layer1(flat_image)\n",
        "print(f\"Size after Linear: {hidden1.size()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J168Qg74gWHK"
      },
      "source": [
        "Линейный слой, в отличие от слоя `nn.Flatten`, имеет обучаемые параметры — веса и смещения. Они хранятся как объекты специального класса `torch.nn.parameter.Parameter` и содержат в себе тензоры собственно с величинами параметров. Получить доступ к ним можно, обратившись к атрибутам слоя `.weight` и `.bias` соответственно."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnwggUAcgWHL",
        "outputId": "3893691a-fb4c-436d-ae8e-07cda8527d89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of linear layer weights: torch.Size([512, 784])\n",
            "Type of linear layer weights: <class 'torch.nn.parameter.Parameter'>\n",
            "\n",
            "Size of linear layer biases: torch.Size([512])\n",
            "Type of linear layer biases: <class 'torch.nn.parameter.Parameter'>\n"
          ]
        }
      ],
      "source": [
        "print(f\"Size of linear layer weights: {layer1.weight.size()}\")\n",
        "print(f\"Type of linear layer weights: {type(layer1.weight)}\")\n",
        "\n",
        "print(f\"\\nSize of linear layer biases: {layer1.bias.size()}\")\n",
        "print(f\"Type of linear layer biases: {type(layer1.bias)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Aymimr7gWHL"
      },
      "source": [
        "Теперь применим функцию ReLU к выходному значению линейного слоя:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CfB2ga1gWHL",
        "outputId": "28c8f346-9176-456b-fa0a-51e9f3f2b7fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before ReLU:  tensor([[-1.0737, -0.3183, -0.0132,  ..., -0.2443, -0.4513,  0.5970],\n",
            "        [-0.8840,  0.4269, -0.2052,  ..., -0.7458,  0.0186,  0.0340],\n",
            "        [ 0.8274, -0.5595, -0.1720,  ..., -0.0934, -0.0285,  0.4067]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "After ReLU:  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.5970],\n",
            "        [0.0000, 0.4269, 0.0000,  ..., 0.0000, 0.0186, 0.0340],\n",
            "        [0.8274, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.4067]],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "\n",
            " Size after ReLU:  torch.Size([3, 512])\n"
          ]
        }
      ],
      "source": [
        "activations1 = nn.ReLU()(hidden1)\n",
        "\n",
        "print(f\"Before ReLU:  {hidden1}\")\n",
        "print(f\"After ReLU:  {activations1}\")\n",
        "print(f\"\\n Size after ReLU:  {activations1.size()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jM3CFMYUgWHM"
      },
      "source": [
        "Все описанные выше слои можно задать одной последовательностью при помощи подмодуля nn.Sequential:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocIPV0rMgWHM",
        "outputId": "8595d503-2f3d-493f-af4b-d4d68bbfded1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output size: torch.Size([3, 10])\n"
          ]
        }
      ],
      "source": [
        "seq_modules = nn.Sequential(flatten, layer1, nn.ReLU(), nn.Linear(512, 10))\n",
        "\n",
        "sample_batch = torch.rand(3, 1, 28, 28)\n",
        "logits = seq_modules(sample_batch)\n",
        "\n",
        "print(f\"Output size: {logits.size()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fObpdXergWHM"
      },
      "source": [
        "И в завершение применим функцию nn.Softmax для предсказания вероятностей выходных классов:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRo0nhIYgWHM",
        "outputId": "74f90e02-444d-4dd3-bc3c-0dfd939328f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size after Softmax: torch.Size([3, 512])\n"
          ]
        }
      ],
      "source": [
        "softmax = nn.Softmax(dim=1)\n",
        "\n",
        "pred_probab = softmax(hidden1)\n",
        "\n",
        "print(f\"Size after Softmax: {pred_probab.size()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1REkfFfgWHN"
      },
      "source": [
        "В примере ниже мы проходимся по всем параметрам модели, и для каждого тензора параметров выводим его размер."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbDtoNO1gWHN",
        "outputId": "d842ca7c-e632-4bcb-83a5-dc6195b4dc07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model structure: Network(\n",
            "  (hidden): Linear(in_features=3, out_features=2, bias=True)\n",
            "  (output): Linear(in_features=2, out_features=1, bias=True)\n",
            "  (activation): ReLU()\n",
            ")\n",
            "\n",
            "Layer: hidden.weight              Size: torch.Size([2, 3])\n",
            "Layer: hidden.bias                Size: torch.Size([2])\n",
            "Layer: output.weight              Size: torch.Size([1, 2])\n",
            "Layer: output.bias                Size: torch.Size([1])\n"
          ]
        }
      ],
      "source": [
        "print(f\"Model structure: {model}\\n\")\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name:25}  Size: {param.size()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioMlSATAgWHP"
      },
      "source": [
        "## Задание: написать архитектуру нейронной сети, на вход которой подаётся изображение размера $28 \\times 28$ с одним скрытым линейным слоем, состоящим из 256 нейронов с функцией активации Sigmoid и выходным слоем, состоящим из 10 нейронов. К выходному слою применить функцию Softmax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHftHFUagWHQ",
        "outputId": "35d75c0b-a194-459e-a7c5-63f6b835fff0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.0486, 0.0969, 0.1084, 0.1129, 0.0805, 0.1189, 0.1141, 0.0752, 0.1576,\n",
            "         0.0868]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "input = torch.randn((1, 784))\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.hidden = nn.Linear(784, 256)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "        self.output = nn.Linear(256, 10)\n",
        "\n",
        "\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.hidden(x)\n",
        "        x = self.sigmoid(x)\n",
        "\n",
        "\n",
        "        x = self.output(x)\n",
        "\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "net = Network()\n",
        "output = net.forward(input)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQpwypYagWHQ"
      },
      "source": [
        "### Выбор устройства (device) для обучения\n",
        "\n",
        "Мы бы хотели иметь возможность обучать модель на аппаратном ускорителе, таком как GPU, если он доступен. Проверим, доступен ли нам ускоритель [`torch.cuda`](https://pytorch.org/docs/stable/notes/cuda.html), иначе продолжим вычисления на CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BUmcscLgWHR",
        "outputId": "cdfc9021-5a9e-48d0-8d6d-05658c033641"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAx1Cl34gWHR"
      },
      "source": [
        "## Задание: создать нейронную сеть, указанную на картинке:\n",
        "\n",
        "<img src=\"assets/mlp_mnist.png\" width='1000'>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkvpYnvfgWHR",
        "outputId": "44b9ba4b-724f-4162-ee66-9861a562b5f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Network(\n",
            "  (input_layer): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (hidden_layer1): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (hidden_layer2): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "\n",
        "\n",
        "        self.input_layer = nn.Linear(784, 128)\n",
        "\n",
        "        self.hidden_layer1 = nn.Linear(128, 64)\n",
        "\n",
        "        self.hidden_layer2 = nn.Linear(64, 10)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.input_layer(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "\n",
        "        x = self.hidden_layer1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "\n",
        "        x = self.hidden_layer2(x)\n",
        "\n",
        "\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "model = Network()\n",
        "\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qrh_W8HVgWHS"
      },
      "source": [
        "Теперь запишите эту же нейронную сеть с использованием модуля [`nn.Sequential`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wHLejwEgWHS",
        "outputId": "206b5408-bc27-4222-b64c-77d292022459"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (5): Softmax(dim=1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "input_size = 784\n",
        "hidden_sizes = [128, 64]\n",
        "output_size = 10\n",
        "\n",
        "\n",
        "model1 = nn.Sequential(\n",
        "    nn.Linear(input_size, hidden_sizes[0]),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden_sizes[1], output_size),\n",
        "    nn.Softmax(dim=1)\n",
        ")\n",
        "\n",
        "\n",
        "print(model1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY6u4BtkgWHS"
      },
      "source": [
        "Для создания нейронной сети можно также пользоваться модулем [OrderedDict](https://docs.python.org/3/library/collections.html#collections.OrderedDict):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmVAR_-dgWHT",
        "outputId": "51650c46-e76b-4567-d4d8-0f864daba9aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (relu1): ReLU()\n",
            "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (relu2): ReLU()\n",
            "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "input_size = 784\n",
        "hidden_sizes = [128, 64]\n",
        "output_size = 10\n",
        "\n",
        "model2 = nn.Sequential(OrderedDict([\n",
        "    ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
        "    ('relu1', nn.ReLU()),\n",
        "    ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
        "    ('relu2', nn.ReLU()),\n",
        "    ('output', nn.Linear(hidden_sizes[1], output_size)),\n",
        "    ('softmax', nn.Softmax(dim=1))\n",
        "]))\n",
        "\n",
        "\n",
        "print(model2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdSZ3_htgWHT"
      },
      "source": [
        "Чтобы явно увидеть веса модели model2, надо использовать метод parameters():"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4rCnPytgWHT",
        "outputId": "b4241272-22be-4c05-9a9a-622c4ba65e7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0220, -0.0219, -0.0328,  ..., -0.0002,  0.0248,  0.0188],\n",
            "        [ 0.0099, -0.0155, -0.0237,  ..., -0.0201,  0.0213,  0.0333],\n",
            "        [ 0.0175,  0.0222, -0.0086,  ..., -0.0187,  0.0001, -0.0240],\n",
            "        ...,\n",
            "        [-0.0204,  0.0034, -0.0147,  ...,  0.0057,  0.0319,  0.0248],\n",
            "        [-0.0319,  0.0151,  0.0251,  ..., -0.0200, -0.0265,  0.0216],\n",
            "        [ 0.0040,  0.0104, -0.0288,  ..., -0.0164,  0.0231, -0.0262]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0071, -0.0228, -0.0130, -0.0222,  0.0184,  0.0171, -0.0248, -0.0352,\n",
            "         0.0164, -0.0257,  0.0037, -0.0004,  0.0338,  0.0324,  0.0344,  0.0022,\n",
            "         0.0239, -0.0231,  0.0145, -0.0280,  0.0188,  0.0049, -0.0239, -0.0357,\n",
            "         0.0106,  0.0343, -0.0010, -0.0074, -0.0179,  0.0155, -0.0328, -0.0119,\n",
            "        -0.0208, -0.0094,  0.0096, -0.0078, -0.0333, -0.0109,  0.0156, -0.0173,\n",
            "        -0.0136, -0.0305,  0.0270, -0.0211, -0.0062,  0.0283,  0.0252, -0.0089,\n",
            "        -0.0004,  0.0251, -0.0228, -0.0008, -0.0140, -0.0300, -0.0165,  0.0125,\n",
            "        -0.0168,  0.0231,  0.0269, -0.0114,  0.0186, -0.0067, -0.0336,  0.0114,\n",
            "         0.0077,  0.0090,  0.0335, -0.0182, -0.0170, -0.0022, -0.0258, -0.0223,\n",
            "         0.0271, -0.0337, -0.0243, -0.0211,  0.0001, -0.0113,  0.0020,  0.0040,\n",
            "        -0.0031,  0.0106,  0.0216,  0.0159, -0.0261, -0.0123, -0.0238, -0.0135,\n",
            "        -0.0356, -0.0188,  0.0289,  0.0234,  0.0236, -0.0321, -0.0049,  0.0036,\n",
            "        -0.0330,  0.0178, -0.0168, -0.0215,  0.0340,  0.0242,  0.0175, -0.0002,\n",
            "         0.0276, -0.0278,  0.0105, -0.0211,  0.0032,  0.0333,  0.0204, -0.0116,\n",
            "         0.0267,  0.0058,  0.0111, -0.0228,  0.0219,  0.0249, -0.0080,  0.0168,\n",
            "        -0.0337, -0.0313, -0.0343,  0.0163, -0.0014,  0.0136, -0.0263, -0.0292],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 1.0320e-02,  4.1089e-02, -4.7487e-02,  ..., -2.1642e-02,\n",
            "         -9.7422e-05, -4.4580e-02],\n",
            "        [-4.4871e-02, -3.4395e-02, -5.0259e-02,  ..., -3.3550e-02,\n",
            "         -3.1997e-02, -2.4368e-02],\n",
            "        [ 3.7229e-02,  8.1598e-02,  2.8791e-02,  ...,  3.5015e-02,\n",
            "          3.0576e-02,  7.4709e-02],\n",
            "        ...,\n",
            "        [ 8.7456e-02,  6.9571e-02,  5.7664e-02,  ..., -7.6333e-02,\n",
            "         -6.5055e-02,  5.5372e-02],\n",
            "        [-7.5831e-02, -7.5885e-02, -5.6318e-02,  ...,  3.9212e-02,\n",
            "          3.1367e-02,  1.8677e-02],\n",
            "        [-2.0104e-02, -2.1668e-02,  2.1112e-02,  ..., -2.7902e-02,\n",
            "         -3.7968e-02, -5.5558e-02]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0359, -0.0201, -0.0801,  0.0437,  0.0075,  0.0340, -0.0553, -0.0643,\n",
            "         0.0204,  0.0694, -0.0628,  0.0875,  0.0379,  0.0182,  0.0219,  0.0039,\n",
            "         0.0179,  0.0012, -0.0826, -0.0478,  0.0817, -0.0079,  0.0724, -0.0271,\n",
            "        -0.0603,  0.0110, -0.0612, -0.0395, -0.0521,  0.0091, -0.0847,  0.0771,\n",
            "         0.0622, -0.0423, -0.0375, -0.0128,  0.0049,  0.0156,  0.0216, -0.0441,\n",
            "        -0.0513,  0.0214, -0.0633, -0.0397,  0.0447,  0.0061, -0.0181, -0.0790,\n",
            "        -0.0121,  0.0816, -0.0867, -0.0086, -0.0631, -0.0294,  0.0103, -0.0082,\n",
            "        -0.0200,  0.0626, -0.0085,  0.0407,  0.0872, -0.0569,  0.0487,  0.0104],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-9.6397e-02,  1.1332e-01,  1.2265e-02, -1.0409e-01, -9.8956e-02,\n",
            "         -6.2411e-02,  1.0179e-01, -9.6490e-02, -4.5518e-02,  4.9634e-02,\n",
            "         -2.0109e-02,  3.6934e-04,  1.3464e-02, -4.6521e-02, -1.6641e-02,\n",
            "         -1.4970e-02,  4.1835e-02, -1.0036e-01,  8.6362e-02, -9.2142e-02,\n",
            "         -1.8888e-02,  5.6220e-02, -4.2084e-02,  9.2766e-02, -1.0264e-01,\n",
            "          6.0097e-02,  1.0900e-01,  2.8917e-02, -5.3342e-02,  5.4865e-02,\n",
            "         -1.1744e-01,  1.7639e-02,  7.1558e-02,  6.8004e-02,  3.0738e-02,\n",
            "          6.2254e-02, -3.1465e-03, -1.1104e-01,  5.4795e-03,  8.9987e-02,\n",
            "         -5.2233e-02,  5.8588e-02,  3.7793e-02, -5.5185e-02, -1.2062e-01,\n",
            "         -5.5035e-02, -3.3850e-02, -7.8858e-03,  4.9942e-02,  3.3000e-02,\n",
            "          9.7865e-03, -8.4178e-02,  5.4254e-02,  9.7062e-02, -6.1781e-02,\n",
            "         -5.2411e-02, -1.2270e-01, -9.3244e-02, -5.9019e-02, -1.2398e-01,\n",
            "         -3.1710e-02,  6.2433e-02, -3.1033e-02, -2.0625e-03],\n",
            "        [-9.9944e-02, -3.6970e-02, -1.1120e-01,  8.6927e-02,  6.2940e-02,\n",
            "         -7.2738e-02, -4.3098e-02,  1.2237e-01,  1.2284e-01, -2.0655e-02,\n",
            "          9.7134e-02, -2.9497e-02,  4.3774e-02, -7.1772e-02, -1.0353e-01,\n",
            "         -1.0809e-01, -2.8590e-02,  2.9784e-02, -3.0748e-03,  1.2007e-01,\n",
            "         -2.9138e-02, -8.8626e-02,  9.0933e-02, -8.0699e-02,  7.0676e-02,\n",
            "          8.9911e-02, -3.9704e-02, -1.2027e-01,  1.1716e-01, -2.1980e-03,\n",
            "         -3.2768e-02,  1.2309e-01, -5.5754e-02,  4.4923e-02, -1.0758e-01,\n",
            "          8.8278e-02,  2.5945e-02, -1.1093e-01,  1.2187e-01, -9.2430e-02,\n",
            "          9.8434e-02,  6.0824e-02, -5.1627e-02,  1.0373e-01,  8.9643e-02,\n",
            "         -9.9189e-03, -3.2111e-02, -7.4090e-04, -4.1321e-03,  1.2460e-01,\n",
            "          5.9966e-02,  4.1651e-02, -9.6447e-02,  2.1077e-02, -7.2978e-03,\n",
            "          4.3948e-02, -3.1288e-02, -2.5440e-02,  9.2049e-02, -1.0261e-01,\n",
            "         -1.0747e-01, -2.6305e-02,  4.7987e-02, -7.2210e-03],\n",
            "        [-8.6270e-02, -8.7406e-02,  1.1696e-01,  3.5506e-02,  1.2386e-01,\n",
            "         -7.6069e-02, -1.1058e-01,  3.0847e-02, -2.0096e-02,  7.9595e-02,\n",
            "         -7.2744e-02,  7.1246e-02,  4.1780e-02,  9.8674e-02,  9.9390e-02,\n",
            "          1.6636e-02,  4.8350e-02, -1.6306e-02,  1.8347e-02, -3.2768e-02,\n",
            "          1.0604e-01, -4.0711e-02, -1.8292e-02, -3.6133e-02,  8.3104e-02,\n",
            "         -1.0305e-02, -8.7233e-02,  1.0638e-01,  6.4134e-02,  9.5585e-02,\n",
            "          9.9227e-02, -6.3091e-02, -8.8909e-02, -1.0980e-01, -4.3519e-02,\n",
            "         -3.5067e-03,  7.9244e-02, -9.7725e-02,  5.4007e-03, -6.8991e-02,\n",
            "          2.8648e-02,  8.4059e-02,  6.3586e-02, -8.2895e-02, -9.2052e-02,\n",
            "         -1.1909e-01,  6.2407e-02, -8.4530e-03,  3.8306e-02,  1.0868e-01,\n",
            "         -1.1726e-01,  1.0330e-01,  4.4806e-02,  1.3692e-02, -9.7489e-02,\n",
            "         -5.3020e-02,  2.4054e-02,  3.9280e-02, -2.6425e-02, -1.1065e-01,\n",
            "         -1.1506e-01, -1.1594e-01, -2.4764e-02,  1.5164e-02],\n",
            "        [-7.0635e-02, -5.1035e-02, -7.1654e-02,  6.6799e-02, -6.5587e-02,\n",
            "          4.4931e-02,  7.7955e-02,  4.9220e-02,  5.8945e-02, -5.6924e-03,\n",
            "          1.1672e-01,  9.9266e-02, -5.5250e-02,  2.9739e-02,  4.8707e-02,\n",
            "          6.5841e-02, -1.2316e-01,  4.8775e-02, -9.4435e-02, -8.0535e-02,\n",
            "          5.1288e-02, -8.1574e-02, -8.4598e-02, -1.7452e-02, -1.1290e-01,\n",
            "         -5.8635e-02,  2.2809e-03, -8.5797e-03,  4.0588e-02, -5.5578e-02,\n",
            "          6.7969e-02, -1.0437e-01,  1.0133e-01, -4.2886e-04, -1.1398e-01,\n",
            "         -6.9190e-03, -1.2067e-01, -1.2093e-01, -9.9529e-02, -9.4964e-02,\n",
            "         -6.8648e-02, -3.9378e-03,  7.7138e-02,  6.2182e-02,  6.8454e-02,\n",
            "         -3.0394e-02, -7.0687e-02,  3.0740e-02,  2.7407e-02, -4.7354e-02,\n",
            "         -1.1444e-01,  4.4317e-02,  1.5497e-02, -1.0410e-01, -1.2225e-02,\n",
            "          3.5064e-02, -8.6151e-02,  8.8658e-02,  5.1776e-02, -9.8095e-02,\n",
            "         -1.1054e-01, -1.0208e-01, -1.1548e-01,  6.0521e-02],\n",
            "        [-4.2289e-02,  1.0939e-01,  1.0441e-02, -5.2028e-02,  9.9796e-02,\n",
            "          2.5930e-02, -5.7530e-02,  1.2432e-01,  9.9317e-02, -7.3294e-02,\n",
            "         -8.0114e-03,  1.0838e-01, -7.7513e-02,  2.1710e-02,  1.1693e-01,\n",
            "         -9.2554e-02, -8.4614e-03, -2.0731e-02,  9.6166e-02, -1.1804e-01,\n",
            "          4.4925e-02,  8.2285e-02,  4.0729e-02,  8.6441e-02,  1.0890e-01,\n",
            "         -8.4123e-02,  1.0675e-01, -1.2374e-01, -6.0237e-02,  4.4453e-02,\n",
            "          1.1426e-01, -1.0683e-01,  1.0672e-01,  1.0090e-01,  3.3123e-02,\n",
            "         -2.9845e-02, -5.1856e-02, -9.6688e-02,  1.2741e-03,  6.7465e-04,\n",
            "          2.6635e-02, -1.1244e-01, -1.0963e-01, -1.2256e-01, -2.4221e-03,\n",
            "         -4.9446e-02,  7.9489e-03,  1.4090e-02,  8.1565e-02,  5.1857e-02,\n",
            "         -8.0368e-02,  1.2242e-03,  7.6424e-02, -1.1078e-01, -1.2451e-01,\n",
            "         -2.4608e-02,  4.7457e-02, -1.0069e-01,  2.3525e-02,  1.1435e-01,\n",
            "         -3.9886e-02,  1.8829e-03, -1.4100e-02,  5.0746e-02],\n",
            "        [-1.7938e-03, -2.3590e-02, -1.0781e-01,  2.5854e-02, -2.6566e-02,\n",
            "         -9.4721e-02,  6.7883e-02,  7.2102e-02, -3.5305e-02, -8.8070e-02,\n",
            "         -9.4206e-03,  8.6243e-02, -9.0733e-02, -7.7869e-02,  1.0560e-01,\n",
            "         -1.0776e-01, -6.2194e-02,  5.3811e-03, -3.6416e-02, -1.6965e-02,\n",
            "          3.5386e-02,  4.7633e-02,  3.3401e-02, -4.0902e-02, -1.0906e-01,\n",
            "         -1.0845e-01, -6.7562e-05, -1.1241e-01, -5.4929e-02,  6.4229e-02,\n",
            "         -1.5137e-02,  6.5325e-03, -4.8123e-02, -1.1847e-01,  3.4322e-02,\n",
            "         -4.1036e-02, -6.0820e-02, -1.1248e-01, -1.1638e-01,  9.9474e-02,\n",
            "         -9.5825e-02,  1.7728e-02,  1.2265e-01, -3.6792e-02, -7.9396e-02,\n",
            "         -6.8859e-02, -4.1323e-02,  1.6684e-02,  2.0325e-02,  3.3979e-02,\n",
            "          2.1563e-02, -1.1721e-01, -7.7826e-02,  2.6910e-02,  7.1821e-02,\n",
            "         -1.1872e-01,  7.8685e-02, -6.8701e-02,  1.0123e-01, -4.0440e-03,\n",
            "          7.1537e-02, -8.4562e-02,  9.1343e-02,  9.0570e-02],\n",
            "        [-1.1855e-01,  9.7233e-03,  1.1063e-01,  9.7437e-02,  1.0629e-01,\n",
            "          6.8720e-04,  1.2987e-02, -6.5072e-02,  6.1505e-03,  6.2399e-02,\n",
            "         -1.2054e-01, -9.9645e-02,  1.1112e-01,  3.3385e-02,  7.5577e-02,\n",
            "         -6.0358e-02,  2.6780e-02, -1.2477e-01, -3.1522e-02, -3.7681e-02,\n",
            "         -1.1594e-01, -9.7959e-02, -8.6464e-02,  1.1358e-01, -7.4307e-02,\n",
            "         -1.0751e-01,  6.5704e-02,  7.4655e-02, -1.6190e-03,  4.9527e-02,\n",
            "          9.6654e-02, -6.2410e-02, -7.2069e-02, -1.4147e-02,  3.4521e-02,\n",
            "         -1.1278e-01, -1.0859e-01, -3.1137e-02,  5.6331e-02,  1.1816e-01,\n",
            "         -1.1066e-01,  6.1724e-02,  9.1314e-02, -1.0947e-02,  7.3856e-02,\n",
            "         -6.6864e-02, -1.0317e-01, -1.0726e-01,  4.8869e-02,  7.6001e-02,\n",
            "          5.7825e-02, -2.2555e-02,  7.0271e-02, -9.6316e-02,  1.3765e-03,\n",
            "         -1.0710e-01, -1.7597e-02, -1.0872e-01, -1.0925e-01,  1.0715e-01,\n",
            "          1.2210e-01,  5.4458e-03, -2.7061e-02, -1.5044e-02],\n",
            "        [-5.3901e-02,  1.0591e-01,  4.7478e-02, -5.0906e-02, -4.5366e-03,\n",
            "         -3.1725e-05, -4.8959e-02,  9.2471e-02, -8.0066e-02, -5.6697e-02,\n",
            "          1.1352e-01, -9.5199e-02, -1.0021e-02, -1.0597e-01, -1.1988e-01,\n",
            "          1.0541e-01,  4.9032e-02,  1.1109e-01, -9.8384e-02, -1.2280e-01,\n",
            "          3.8422e-02,  6.9224e-02,  1.0000e-02,  8.7225e-02,  7.2394e-02,\n",
            "          4.5946e-02,  9.3046e-03,  3.1409e-04, -4.4326e-02, -1.7016e-02,\n",
            "         -1.1320e-01,  6.6824e-02, -2.8801e-02,  3.2300e-02, -1.1765e-01,\n",
            "          7.2067e-02,  4.6472e-02, -9.1765e-02, -9.7083e-03, -6.2353e-02,\n",
            "         -5.0036e-02, -8.9835e-02,  4.1395e-02, -1.2517e-02,  5.7949e-02,\n",
            "         -1.2318e-01, -8.4499e-02,  1.1976e-01,  4.8536e-02, -2.5319e-02,\n",
            "         -8.6452e-02, -4.6288e-02,  1.2171e-01, -2.9421e-02,  2.5947e-02,\n",
            "         -6.2810e-02, -6.5183e-02,  2.3141e-02,  9.9166e-02, -1.7049e-02,\n",
            "         -9.9410e-02,  8.1934e-02,  8.0936e-02,  3.5774e-02],\n",
            "        [ 1.0460e-01,  7.7308e-02,  4.7764e-02,  8.0877e-02,  6.3277e-02,\n",
            "          7.6477e-02, -1.0329e-01,  5.3042e-02, -3.2371e-02,  8.0984e-02,\n",
            "          6.0943e-02, -2.2374e-02, -4.5578e-02,  6.8586e-02, -9.4983e-03,\n",
            "          3.5341e-02,  1.0966e-01,  6.4194e-02, -1.0651e-01,  1.0498e-01,\n",
            "         -6.9617e-02, -7.2950e-03, -1.1309e-02,  2.3696e-02, -4.2128e-02,\n",
            "          8.9645e-02, -3.8257e-02,  1.1637e-01, -9.7191e-02,  1.0077e-01,\n",
            "          2.4824e-02, -1.1615e-01, -1.1898e-01, -1.1692e-01, -8.0898e-02,\n",
            "         -5.2785e-02, -1.1633e-01,  8.2349e-02,  8.2178e-02,  2.3917e-02,\n",
            "         -1.2100e-01, -6.8597e-02, -4.2992e-02, -2.1687e-02, -6.1041e-02,\n",
            "         -5.0726e-02, -1.9314e-02, -1.0240e-01, -4.6004e-02, -6.3342e-02,\n",
            "         -1.1853e-01,  1.2456e-01, -2.7015e-02, -1.1510e-01, -8.7282e-02,\n",
            "          1.0141e-01, -1.0611e-01,  5.8074e-02,  5.5954e-02, -5.4989e-02,\n",
            "          8.7070e-02, -5.4494e-02,  6.9516e-02, -2.7000e-02],\n",
            "        [-1.8255e-02, -8.7060e-02, -1.0323e-01, -9.3299e-02, -2.8066e-02,\n",
            "          7.1766e-02, -6.5532e-02, -1.7013e-02,  8.7864e-02,  2.7403e-02,\n",
            "         -4.3578e-02,  8.8532e-02, -1.1715e-01, -1.0028e-01, -1.0083e-02,\n",
            "          1.2125e-01, -1.1111e-01, -1.2251e-01, -4.0847e-02, -9.3956e-03,\n",
            "         -1.0562e-01,  6.0067e-02, -4.7522e-02,  9.1702e-02, -1.0144e-01,\n",
            "         -3.5986e-02,  5.5272e-03,  4.2846e-02,  5.8120e-02,  8.9776e-02,\n",
            "         -9.5027e-02, -8.7033e-03, -3.0458e-02, -3.8646e-02,  2.2233e-02,\n",
            "         -5.4330e-02, -2.1742e-02,  9.1076e-02, -1.1555e-01,  5.2456e-02,\n",
            "         -8.5819e-02,  3.5511e-02, -7.1302e-02, -8.7582e-02,  1.0563e-01,\n",
            "          7.6655e-02,  2.1082e-02, -4.9303e-02, -1.0210e-01,  8.7279e-02,\n",
            "          3.9432e-02, -4.6359e-02,  4.7279e-02,  6.9823e-02,  3.1996e-02,\n",
            "         -3.6559e-02, -1.1905e-01,  5.4337e-02,  1.1514e-01, -3.1156e-02,\n",
            "         -1.1589e-01,  8.6371e-02,  1.0570e-02,  6.7406e-02]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0040,  0.0440, -0.0133,  0.0111, -0.0124, -0.0623, -0.0520,  0.1220,\n",
            "         0.0321, -0.0793], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "params = model2.parameters()\n",
        "\n",
        "\n",
        "for param in params:\n",
        "    print(param)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}