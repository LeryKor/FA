{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PcL7r1hqySq"
      },
      "source": [
        "# Предобработка текста"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-sGLT0vp4jt"
      },
      "source": [
        "## Часть 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wn8EWAjnr18g"
      },
      "source": [
        "### Токенизация"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btBdBLxbgrNV",
        "outputId": "88f89068-89c2-4553-d7c2-999bcee2f9d7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq-QOD9NlO_Q",
        "outputId": "57712dd5-45aa-4e30-8034-f90b9913892d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['all', 'work', 'and', 'no', 'play', 'makes', 'jack', 'a', 'dull', 'boy', ',', 'all', 'work', 'and', 'no', 'play']\n"
          ]
        }
      ],
      "source": [
        "data = \"All work and no play makes jack a dull boy, all work and no play\"\n",
        "tokens = word_tokenize(data.lower())\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFDKUzkS6Mci",
        "outputId": "b3382fe3-7681-4f9a-b019-55a7d0d2c360"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['I was going home when she rung.', 'It was a surprise.']\n"
          ]
        }
      ],
      "source": [
        "print(sent_tokenize(\"I was going home when she rung. It was a surprise.\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQoG7qznyuf5"
      },
      "source": [
        "[<img src=\"https://raw.githubusercontent.com/natasha/natasha-logos/master/natasha.svg\">](https://github.com/natasha/natasha)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPeApu2mwYxY"
      },
      "source": [
        "[Razdel](https://natasha.github.io/razdel/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwJj5Z2fvbeN"
      },
      "outputs": [],
      "source": [
        "!pip install -q razdel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uy58Xd_vve-z",
        "outputId": "ce0a47f7-2cbe-4e2c-c72d-0b458d0fd19b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Substring(0, 13, 'Кружка-термос'),\n",
              " Substring(14, 16, 'на'),\n",
              " Substring(17, 20, '0.5'),\n",
              " Substring(20, 21, 'л'),\n",
              " Substring(22, 23, '('),\n",
              " Substring(23, 28, '50/64'),\n",
              " Substring(29, 32, 'см³'),\n",
              " Substring(32, 33, ','),\n",
              " Substring(34, 37, '516'),\n",
              " Substring(37, 38, ';'),\n",
              " Substring(38, 41, '...'),\n",
              " Substring(41, 42, ')')]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from razdel import tokenize, sentenize\n",
        "text = 'Кружка-термос на 0.5л (50/64 см³, 516;...)'\n",
        "list(tokenize(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrmhCpNdQo6r"
      },
      "source": [
        "#### Регулярные выражения\n",
        "\n",
        "Исчерпывающий пост https://habr.com/ru/post/349860/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IccRpcG06Mfd",
        "outputId": "2864d2c7-68c5-4e07-9889-c90e64586ed7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['super', 'c', 'a', 'a', 'c', 'a', 'c']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "word = 'supercalifragilisticexpialidocious'\n",
        "re.findall('[abc]|up|super', word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Je8YPHLZPJW7",
        "outputId": "6ff0745d-24b5-4d8b-c0bb-c518db771f47"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['49', '432', '312']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "re.findall('\\d{1,3}', 'These are some numbers: 49 and 432312')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fzde8MX1PJXA",
        "outputId": "f66a4263-5025-4248-e439-9cef0a8a614d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'How to split text'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "re.sub('[,\\.?!]','','How, to? split. text!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyswV9nuPJXF",
        "outputId": "50185d5b-e118-4df1-9de8-0df4fd419298"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['I', 'can', 'play', 'football']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "re.sub('[^A-z]',' ','I 123 can 45 play 67 football').split()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz0wIRkRswOQ"
      },
      "source": [
        "### Удаление неинформативных слов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trdPOBM2jEMf"
      },
      "source": [
        "#### N-граммы\n",
        "\n",
        "<img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--466CQV1q--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/78nf1vryed8h1tz05fim.gif\" height=400>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYEBfCxLic3R",
        "outputId": "16bb55d4-bf66-44de-ad09-aff8850d727b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('all',), ('work',), ('and',), ('no',), ('play',)]\n",
            "[('all', 'work'), ('work', 'and'), ('and', 'no'), ('no', 'play'), ('play', 'makes')]\n"
          ]
        }
      ],
      "source": [
        "unigram = list(nltk.ngrams(tokens, 1))\n",
        "bigram = list(nltk.ngrams(tokens, 2))\n",
        "print(unigram[:5])\n",
        "print(bigram[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AFeZqejmWwN",
        "outputId": "8f9fff61-090e-4e05-adc3-f9052610d5bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Популярные униграммы:  [(('all',), 2), (('work',), 2), (('and',), 2), (('no',), 2), (('play',), 2)]\n",
            "Популярные биграммы:  [(('all', 'work'), 2), (('work', 'and'), 2), (('and', 'no'), 2), (('no', 'play'), 2), (('play', 'makes'), 1)]\n"
          ]
        }
      ],
      "source": [
        "from nltk import FreqDist\n",
        "print('Популярные униграммы: ', FreqDist(unigram).most_common(5))\n",
        "print('Популярные биграммы: ', FreqDist(bigram).most_common(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3W3jJ56hnBFu"
      },
      "source": [
        "#### Стоп-слова"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIBwQ3nBnEfV",
        "outputId": "5f6c8413-a652-4ea6-9b6d-450e099075cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1nk-TqEslRl",
        "outputId": "e56801a2-c8bf-479a-f1e8-ed312cdb3a9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'myself', 'how', 'but', 'ourselves', 'wasn', 'her', 'being', \"shan't\", 'just', 'it', \"aren't\", 'him', \"you've\", 'himself', 'been', 've', 'up', \"wouldn't\", 'through', 'yours', 'these', 'between', 'from', 'are', 'because', 'if', 'which', 'own', 'during', \"wasn't\", 'be', 's', \"won't\", 'those', 'again', 'll', 'don', 'them', 'ain', 'have', 'their', 'weren', 'has', 'as', 're', 'my', 'to', 'what', 'your', 'itself', 'shouldn', 'some', 'off', 'wouldn', \"doesn't\", 'an', 'is', 'having', 'too', 'a', 'such', 'here', 'yourself', \"should've\", 'didn', 'and', 'was', 'most', 'when', 'hasn', 'themselves', 'above', 'mustn', 'by', 'i', 'where', 'no', \"weren't\", 'he', 'theirs', \"hasn't\", 'isn', 'under', 'did', 'our', \"mightn't\", \"shouldn't\", 'of', 'you', 'couldn', 'can', 'does', \"you'd\", 'about', 'further', 'needn', 'after', 'ours', \"haven't\", 'into', 'his', 'against', 'd', 'o', 'with', 'very', \"didn't\", 'out', 'doesn', 'ma', 'while', 'herself', 'y', 'the', 'each', 'won', 'then', 'both', 'aren', 'mightn', 'other', \"mustn't\", 'or', 'whom', 'until', 'am', 'than', 'more', 'me', 'not', 'at', 'same', \"don't\", 'do', 'haven', 'before', 'm', 'below', 'once', 'that', 'who', 'why', 'doing', 'shan', \"hadn't\", \"that'll\", \"needn't\", 'she', 'now', 'for', 'all', 'should', 'on', 'hadn', \"couldn't\", \"it's\", 't', 'had', 'we', 'hers', 'they', 'any', 'only', 'yourselves', 'down', 'its', 'in', \"you're\", 'will', 'over', 'were', 'so', 'there', \"you'll\", 'nor', \"isn't\", 'this', \"she's\", 'few'}\n"
          ]
        }
      ],
      "source": [
        "stopWords = set(stopwords.words('english'))\n",
        "print(stopWords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFkfJm9ktAVa",
        "outputId": "11e85df4-d2e6-4f9f-ff23-f6cc50fee22b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['work', 'play', 'makes', 'jack', 'dull', 'boy', ',', 'work', 'play']\n"
          ]
        }
      ],
      "source": [
        "print([word for word in tokens if word not in stopWords])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5QoqlHiS83f",
        "outputId": "628de9cf-0e10-48ee-e743-448512a7cd13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "print(string.punctuation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh-MYv6e-skM"
      },
      "source": [
        "#### Стемминг vs Лемматизация\n",
        "* ‘Caring’ -> Лемматизация -> ‘Care’\n",
        "* ‘Caring’ -> Стемминг -> ‘Car’"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAUKc1oTiQjf"
      },
      "source": [
        "### Стемминг\n",
        "* процесс нахождения основы слова для заданного исходного слова"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRVu-TrON4sq"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer, SnowballStemmer\n",
        "words = [\"game\", \"gaming\", \"gamed\", \"games\", \"compacted\"]\n",
        "words_ru = ['корова', 'мальчики', 'мужчины', 'столом', 'убежала']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9HTGfsBN9eX",
        "outputId": "e4392b8d-20cb-4a60-9a09-1326d2fdf3f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['game', 'game', 'game', 'game', 'compact']"
            ]
          },
          "execution_count": 32,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ps = PorterStemmer()\n",
        "list(map(ps.stem, words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5qZkB-oODkW",
        "outputId": "b2094c0b-6f4f-431b-801e-107fac105e9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['коров', 'мальчик', 'мужчин', 'стол', 'убежа']"
            ]
          },
          "execution_count": 33,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ss = SnowballStemmer(language='russian')\n",
        "list(map(ss.stem, words_ru))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbTXbi9FJXr1"
      },
      "source": [
        "### Лематизация\n",
        "* процесс приведения словоформы к лемме — её нормальной (словарной) форме"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QF4nnEz00thb"
      },
      "outputs": [],
      "source": [
        "raw = \"\"\"DENNIS: Listen, strange women lying in ponds distributing swords\n",
        "is no basis for a system of government.  Supreme executive power derives from\n",
        "a mandate from the masses, not from some farcical aquatic ceremony.\"\"\"\n",
        "\n",
        "raw_ru = \"\"\"Не существует научных доказательств в пользу эффективности НЛП, оно\n",
        "признано псевдонаукой. Систематические обзоры указывают, что НЛП основано на\n",
        "устаревших представлениях об устройстве мозга, несовместимо с современной\n",
        "неврологией и содержит ряд фактических ошибок.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mljfOAC4n21I",
        "outputId": "5bf02a63-b1cd-4923-cef6-610c496bad73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 61kB 3.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.2MB 7.4MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q pymorphy2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Zez7jnXl5uJ",
        "outputId": "51782962-44ee-431d-c025-5a70226bf9e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "не существовать научный доказательство в польза эффективность нлп, оно \n",
            "признать псевдонаукой. систематический обзор указывают, что нлп основать на \n",
            "устаревший представление о устройство мозга, несовместимый с современный \n",
            "неврология и содержать ряд фактический ошибок.\n"
          ]
        }
      ],
      "source": [
        "# 1\n",
        "import pymorphy2\n",
        "morph = pymorphy2.MorphAnalyzer()\n",
        "pymorphy_results = list(map(lambda x: morph.parse(x), raw_ru.split(' ')))\n",
        "print(' '.join([res[0].normal_form for res in pymorphy_results]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7MDqIvWib4O",
        "outputId": "93dee74a-4769-4473-a6bb-e3e0b71bad2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "denni : listen , strange woman lie in pond distribute sword \n",
            " be no basis for a system of government .   Supreme executive power derive from \n",
            " a mandate from the masse , not from some farcical aquatic ceremony .\n"
          ]
        }
      ],
      "source": [
        "# 2\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "spacy_results = nlp(raw)\n",
        "print(' '.join([token.lemma_ for token in spacy_results]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVC5gjCRk5bD"
      },
      "source": [
        "[Сравнение PyMorphy2 и PyMystem3](https://habr.com/ru/post/503420/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yim_NVYA6MeS"
      },
      "source": [
        "### Part-of-Speech"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2t_MamYKqbSk",
        "outputId": "17c3a9fc-4fc2-4d0f-9353-a76e653cf6f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('не', OpencorporaTag('PRCL')),\n",
              " ('существовать', OpencorporaTag('VERB,impf,intr sing,3per,pres,indc')),\n",
              " ('научный', OpencorporaTag('ADJF,Qual plur,gent')),\n",
              " ('доказательство', OpencorporaTag('NOUN,inan,neut plur,gent')),\n",
              " ('в', OpencorporaTag('PREP')),\n",
              " ('польза', OpencorporaTag('NOUN,inan,femn sing,accs')),\n",
              " ('эффективность', OpencorporaTag('NOUN,inan,femn sing,gent')),\n",
              " ('нлп,', OpencorporaTag('UNKN')),\n",
              " ('оно', OpencorporaTag('NPRO,neut,3per,Anph sing,nomn'))]"
            ]
          },
          "execution_count": 41,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 1\n",
        "[(res[0].normal_form, res[0].tag) for res in pymorphy_results[:9]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Doa85yw6JWea",
        "outputId": "794ec981-0378-4020-e316-f1e2045d8949"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('denni', 'NOUN'),\n",
              " (':', 'PUNCT'),\n",
              " ('listen', 'VERB'),\n",
              " (',', 'PUNCT'),\n",
              " ('strange', 'ADJ'),\n",
              " ('woman', 'NOUN'),\n",
              " ('lie', 'VERB')]"
            ]
          },
          "execution_count": 42,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 2\n",
        "[(token.lemma_, token.pos_) for token in spacy_results[:7]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVGJLVjLtFDp",
        "outputId": "c01be447-80df-4477-c875-28889e7b7e36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 10.5MB 6.2MB/s \n",
            "\u001b[?25h  Building wheel for rnnmorph (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for russian-tagsets (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q rnnmorph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ms2yeEFqrtZ",
        "outputId": "dd9131e0-82bd-46a7-e54e-1bed989ff9fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('не', 'PART', '_'),\n",
              " ('существовать',\n",
              "  'VERB',\n",
              "  'Mood=Ind|Number=Sing|Person=3|Tense=Notpast|VerbForm=Fin|Voice=Act'),\n",
              " ('научный', 'ADJ', 'Case=Gen|Degree=Pos|Number=Plur'),\n",
              " ('доказательство', 'NOUN', 'Case=Gen|Gender=Neut|Number=Plur'),\n",
              " ('в', 'ADP', '_'),\n",
              " ('польза', 'NOUN', 'Case=Acc|Gender=Fem|Number=Sing'),\n",
              " ('эффективность', 'NOUN', 'Case=Gen|Gender=Fem|Number=Sing')]"
            ]
          },
          "execution_count": 44,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 3\n",
        "from rnnmorph.predictor import RNNMorphPredictor\n",
        "predictor = RNNMorphPredictor(language=\"ru\")\n",
        "rnnmorph_result = predictor.predict(raw_ru.split(' '))\n",
        "[(token.normal_form, token.pos, token.tag) for token in rnnmorph_result[:7]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_Slt2R76Mgk"
      },
      "source": [
        "### Named entities recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvB43ZHT6MhR",
        "outputId": "3d490cfc-0b7f-4cb1-f655-7e9ca16f6a2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Apple 0 5 ORG\n",
            "U.K. 27 31 GPE\n",
            "$1 billion 44 54 MONEY\n"
          ]
        }
      ],
      "source": [
        "doc = nlp('Apple is looking at buying U.K. startup for $1 billion')\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0-_oFwwqAwN"
      },
      "source": [
        "## Часть 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIwDfmrYOMfi"
      },
      "source": [
        "### Задача классификации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6DaLniC6MhY"
      },
      "source": [
        "#### 20 newsgroups\n",
        "Датасет с 18000 новостей, сгруппированных по 20 темам."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uS7IJNW6Mhb"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "newsgroups_train = fetch_20newsgroups(subset='train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMbagpJE6Mhh",
        "outputId": "61757285-4b08-44a7-de43-8bdf693be257",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "newsgroups_train.target_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QReW1K46Mhn",
        "outputId": "ba247f9d-98ff-4bd4-f7e0-88662ecb751b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314,)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "newsgroups_train.filenames.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZtRIQmNQ4H0"
      },
      "source": [
        "#### Выполните классификацию текста на подвыборке из 4 тем новостей 3 методами машинного обучения. <br>В качестве метрики возьмите матрицу ошибок. <br>Сделайте выводы по полученным результатам"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhwuCp5B6Mhz",
        "outputId": "9d301c18-be12-4943-c925-a216150c2de5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2159,)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "categories = ['rec.autos', 'talk.religion.misc',\n",
        "              'sci.crypt', 'sci.space']\n",
        "newsgroups_train = fetch_20newsgroups(subset='train',\n",
        "                                      categories=categories)\n",
        "newsgroups_train.filenames.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SFKW6v3KmVEE",
        "outputId": "10bc788d-0a43-4234-92f1-aad085780f3a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/scikit_learn_data/20news_home/20news-bydate-train/talk.religion.misc/82814'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "newsgroups_train.filenames[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOREsv336MiA",
        "outputId": "083daf45-5932-475d-da93-82f1e7f01b15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From: daveb@pogo.wv.tek.com (Dave Butler)\n",
            "Subject: Re: NEW BIBLICAL CONTRADICTIONS [still not] ANSWERED (Judas)\n",
            "Organization: Tektronix, Inc., Wilsonville,  OR.\n",
            "Lines: 180\n",
            "\n",
            "Mr DeCenso, in spite of requiring Scholarly opinion on the hanging of Judas,\n",
            "rejects that the scholarly opinion of the those scholars and then rephrases\n",
            "those scholars opinion on the subject:\n",
            "\n",
            "> ...we do know from Matthew that he did hang himself and Acts probably records\n",
            "> his death.  Although it's possible and plausible that he fell from the hanging\n",
            "> and hit some rocks, thereby bursting open, I can no longer assume that to be\n",
            "> the case.  Therefore, no contradiction.  Matthew did not say Judas died as a\n",
            ">                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "> result of the hanging, did he?  Most scholars believe he iprobably did, but..?\n",
            "> ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "> \n",
            "> I quoted all that to show that I highly regard the scholars' explanations, but\n",
            "> in looking at the texts initially, we can't assume Judas died.  It is, \n",
            "> however, highly probable.                   ^^^^^^\n",
            "\n",
            "and \n",
            "\n",
            "> Also, there is nothing in the Greek to suggest success or failure.  It simply\n",
            "> means \"hang oneself\".\n",
            "\n",
            "Actually, if you do further research as to the Greek word \"apacgw,\" you will\n",
            "find that it does denote success.  Those scholars did indeed have an excellent\n",
            "reason to assume that the suicide was successful.  As I pointed out, I\n",
            "recently checked several Lexicons:\n",
            "\n",
            "\t\"Greek English Lexicon of the New Testament,\" Louw and Nida\n",
            "\t\"Robinson's Greek and English Lexicon of the New Testament\"\n",
            "\t\"Greek English Lexicon of the New Testament,\" Grimm\n",
            "\t\"Word study Concordance,\" Tynsdale\n",
            "\t\"A Greek English Lexicon of the New Testament and other \n",
            "\t early Christian Writings,\" Bauer-Arndt-Gingrich\n",
            "\t\"The New Analytical Greek Lexicon,\" Perschbacher\n",
            "\n",
            "A couple simply stated \"hanged oneself\", and a couple were more explicit \n",
            "and stated that \"apacgw\" means specifically \"kill yourself by hanging.\" A\n",
            "couple also noted that the meaning of one the root words for \"apacgw\" is\n",
            "\"strangle, throttle or choke\" (which pretty much invalidates the guy who\n",
            "suggested to David Joslin that Judas was hung upside down).  One of the best\n",
            "references though, \"Robinson's Greek and English Lexicon of the New\n",
            "Testament,\" not only stated the translation, it gave both the root words, the\n",
            "literal translation, related greek words which use the same roots, and also\n",
            "other presented specific examples of the word in greek literature (to give\n",
            "further context).  \n",
            "\n",
            "The word \"apagchw\" has two root words: \"gchw\" is the \"to strangle\" root, and\n",
            "the root word \"apo\" means literally \"away.\" This root words is included in\n",
            "words which denote a transition.  It can mean a transition in place (eg: the\n",
            "greek word \"apagello\" means to send a message).  \"Apo\" can also denote a\n",
            "change in state and specifically the change from life to death.  Robinson\n",
            "specifically makes comparison to the word \"apokteiuo,\" which means \"to kill.\"\n",
            "In literal meaning the word \"apacgw\" means \"to throttle, strangle to put out\n",
            "of the way,\" and implicitly denotes a change in life state (ie: away from\n",
            "life, to death).  So while the word \"apacgw\" does mean \"to hang,\" it\n",
            "specifically denotes a death as well.  Thus Robinson is quite specific when he\n",
            "state that it means \"to hang oneself, to end one's life by hanging.\" He then\n",
            "notes the the use of \"apacgw\" in Homers Odessy 19:230 to denote context.  He\n",
            "presents that example of \"apacgw\" as being used to explicitly mean \"suicide by\n",
            "hanging.\" Now since there is a perfectly good word for strangling, without the\n",
            "added denotation of \"death,\" and as you insist that the Bible was written by\n",
            "God, and every word is precicely correct, you are stuck with the complete\n",
            "meaning of \"apacgw\" (ie: Since the word \"apacgw\" was used, then death is\n",
            "denoted as the result). \n",
            "\n",
            "By the way, I note that Mr DeCenso also presents an example of \"apacgw\":\n",
            "\n",
            "> In the Septuagint (the Greek translation of the OT used at the time of Jesus),\n",
            "> it's only used in 2 Samuel 17:23 : \"Now when Ahithophel saw that his advice \n",
            "> was not followed, he saddled a donkey, and arose and went home to his house,\n",
            "> to his city. Then he put his household in order, and hanged himself, and \n",
            "> died; and he was buried in his father's tomb.\"   ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "> ^^^^ \n",
            "> Notice that not only is it stated that Ahithophel \"hanged himself\" [Gr. Sept.,\n",
            "> APAGCHO], but it explicitly adds, \"and died\".  Here we have no doubt of the\n",
            "> result.\n",
            "> In Matthew, we are not explicitly told Judas died.\n",
            "\n",
            "Note Mr DeCenso, as you say, the Septuagint was a translation from Hebrew to\n",
            "Greek, and you have not shown the original meaning of the Hebrew (ie\" the the\n",
            "Hebrew say \"and died\"), and thus whether it was simply echoed in the Greek. \n",
            "It should also be pointed out that, regardless of the added \"and died\", the\n",
            "correct translation would still be \"apacgw,\" as the man did indeed die from\n",
            "strangulation (redundant, but correct).  Further, we have evidence that the\n",
            "Septuagint was repeatedly rewritten and reedited (which included versions\n",
            "which contradicted each other), and such editing was not even necessarily\n",
            "executed by Greeks.  Thus I am not sure that you can use the Septuagint as it\n",
            "now stands, as a paragon of ancient greek.  So, what you really need to prove\n",
            "your point Mr DeCenso, is an example, in ancient greek, of someone committing\n",
            "\"apacgw\" and surviving.  Otherwise I would see you as simply making worthless\n",
            "assertions without corresponding evidence. \n",
            "\n",
            "Now I would note Mr DeCenso, that everytime I go out of my way to research it\n",
            "one of your apparently contrived exegisis, I pretty much find it false.  Thus,\n",
            "I think that if you are going to add to the text, something over and above\n",
            "what the source clearly says, then you had better have an explicit Greek or\n",
            "historical source to justify it. \n",
            "\n",
            "By the way, as to Mr Rose's statement about trees around the Potter's Field:\n",
            "\n",
            "> There are still trees around the ledges and a rocky pavement at the bottom.\n",
            "\n",
            "Unless Mr Rose can show that these trees are two thousand years old, or that\n",
            "there are 2000 year old stumps there, or has a 2 thousand year old description\n",
            "of the area which mentions such trees, then it is inappropriate for him to\n",
            "assert that the present placement of trees prove the location of the trees two\n",
            "thousand years ago (after all, things change). \n",
            "\n",
            "Now as to your other argument, ie: that the money Judas used is not the same\n",
            "as the 30 silvers:\n",
            "\n",
            "> As to your second question Mr DeCenso, you ask how we could be sure that the\n",
            "> money with which Judas purchased the land, was indeed for the betrayal, rather\n",
            "> than some other source.  I would point out that in Acts, where it specifically\n",
            "> mention \"the reward of iniquity\" [Acts 1:18], it also specifically mentions\n",
            "> what act of iniquity they were talking about (ie: Acts 1:16 \"...concerning\n",
            "> Judas who was guide to those who arrested Jesus.\").  Now I would point out\n",
            "> that when the Bible describes an act of \"iniquity,\" and then immediately\n",
            "> discusses \"*the* reward of iniquity,\" it would be rather inane to suggest that\n",
            "> it was an action of iniquity other than the one discussed.\"\n",
            "> \n",
            ">  \n",
            "> Notice that in verse 16, the word \"iniquity\" is not used.  Rather, it states\n",
            "> that Judas \"became a guide to those who arrested Jesus\".\n",
            "> But the writer DID NOT stop there...vs. 17, \"for he was numbered with us and\n",
            "> obtained a part in this ministry.\"  What part did Judas play in their ministry?\n",
            ">          ^^^^^^\n",
            "\n",
            "True, Peter (or the author of Acts) does not specifically call Judas' betrayal\n",
            "\"an iniquity,\" but for that matter, neither does John specifically call Judas'\n",
            "actions \"an iniquity\" either.  Further John 13:29 did not say that Judas took\n",
            "the money box, but rather said:\n",
            "\n",
            "    \"Some thought that because, Judas had the money box, Jesus was telling\n",
            "     him \"Buy what we need for the feast\"; or that he should give something\n",
            "     to the poor, So after receiving the morsel he immediately went out, and\n",
            "     it was night.\"\n",
            "\n",
            "Note that it is said that Judas left, it does not say that he took the money\n",
            "box.  Thus when I see your explanation it still seems to me you would choose\n",
            "the a an unproven iniquity, mentioned by another author, in a different\n",
            "book, written at a different time, over the iniquity explicitly mentioned by\n",
            "the author of acts.  I find this forced and contrived. \n",
            "\n",
            "Of course this particular argument becomes moot, since we have have seen\n",
            "evidence that \"apacgw\" means suicide.  You see, since Judas' hanging was\n",
            "successful, he could not have spent the money mentioned in John 13:29, because\n",
            "Matthew and Mark explicitly say the betrayal was on the high holy day (ie:\n",
            "Passover), and thus he could not have spent the money before killing himself\n",
            "the next day.  Thus the money which bought the \"Field of Blood\" would have to\n",
            "have been the 30 pieces of silver (Of course he got the 30 pieces of silver\n",
            "that night as well, and thus couldn't have spent that either.  Oh dear, I\n",
            "believe that the house of cards is comming down). \n",
            "\n",
            "Maybe we should at this point, discuss now whether Jesus was crucified on\n",
            "Friday or Saturday as that is now part of the argument about Judas.\n",
            "\n",
            "By the way, as to where the prophesy of the Potter's field came from (ie: the\n",
            "mention of it in Matthew), you say:\n",
            "\n",
            "> Please, when we are done with this study on his death, remind me to discuss\n",
            "> this with you.\n",
            "\n",
            "I am reminding you now to discuss it now. It's all part of the same verse we\n",
            "are discussing, and I wish you would quit procrastinating and sidestepping \n",
            "these issues.\n",
            " \n",
            "\t\t\t\tLater,\n",
            "\n",
            "\t\t\t\tDave Butler\n",
            "\n",
            "\tA wise man proportions his belief to the evidence.\n",
            "\t\t\t\tDavid Hume, Philosopher\n",
            "\t\t\t\tAn Inquiry Concerning Human Understanding\n",
            "\n",
            "    PS. I would note again, that you are not stating that that Bible\n",
            "    is not possibly inerrant; you are stating that it *IS* inerrant.\n",
            "    Since you have been, by your own admission, presenting merely \"possible\"\n",
            "    reconciliations (I of course don't rate them that highly), then the \n",
            "    best you can do is say that the Bible is \"possibly\" inerrant, not that \n",
            "    it *is* inerrant.\n",
            "\n",
            "3\n"
          ]
        }
      ],
      "source": [
        "print(newsgroups_train.data[0])\n",
        "print(newsgroups_train.target[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zWiY02SjKzz",
        "outputId": "dfb50524-e117-4ed0-91a3-f2cc4125d465"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Почистим данные и преобразуем текста в списки слов"
      ],
      "metadata": {
        "id": "rEFeCAKDOnOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "bof14jPG2Ad5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLRVR7K6xzeL"
      },
      "outputs": [],
      "source": [
        "reg = re.compile(r\"[^a-zA-z ]\")\n",
        "data = np.array(newsgroups_train.data)\n",
        "func = np.vectorize(lambda s: re.sub(r\"[\\^\\]\\[]\",\"\",re.sub(reg, \"\", \"\".join(s.split(\"\\n\")[1:]))).lower())\n",
        "data = func(data)\n",
        "data = [[token.lemma_ for token in nlp(str(s))] for s in data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlRNbwoiBWw3",
        "outputId": "0b489783-3ae4-4a61-c0e1-36ced6b459c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['subject',\n",
              " 're',\n",
              " 'new',\n",
              " 'biblical',\n",
              " 'contradiction',\n",
              " 'still',\n",
              " 'not',\n",
              " 'answer',\n",
              " 'judasorganization',\n",
              " 'tektronix',\n",
              " 'inc',\n",
              " 'wilsonville',\n",
              " ' ',\n",
              " 'orline',\n",
              " 'mr',\n",
              " 'decenso',\n",
              " 'in',\n",
              " 'spite',\n",
              " 'of',\n",
              " 'require',\n",
              " 'scholarly',\n",
              " 'opinion',\n",
              " 'on',\n",
              " 'the',\n",
              " 'hanging',\n",
              " 'of',\n",
              " 'judasreject',\n",
              " 'that',\n",
              " 'the',\n",
              " 'scholarly',\n",
              " 'opinion',\n",
              " 'of',\n",
              " 'the',\n",
              " 'those',\n",
              " 'scholar',\n",
              " 'and',\n",
              " 'then',\n",
              " 'rephrasesthose',\n",
              " 'scholars',\n",
              " 'opinion',\n",
              " 'on',\n",
              " 'the',\n",
              " 'subject',\n",
              " 'we',\n",
              " 'do',\n",
              " 'know',\n",
              " 'from',\n",
              " 'matthew',\n",
              " 'that',\n",
              " 'he',\n",
              " 'do',\n",
              " 'hang',\n",
              " 'himself',\n",
              " 'and',\n",
              " 'act',\n",
              " 'probably',\n",
              " 'record',\n",
              " 'his',\n",
              " 'death',\n",
              " ' ',\n",
              " 'although',\n",
              " 'its',\n",
              " 'possible',\n",
              " 'and',\n",
              " 'plausible',\n",
              " 'that',\n",
              " 'he',\n",
              " 'fall',\n",
              " 'from',\n",
              " 'the',\n",
              " 'hanging',\n",
              " 'and',\n",
              " 'hit',\n",
              " 'some',\n",
              " 'rock',\n",
              " 'thereby',\n",
              " 'burst',\n",
              " 'open',\n",
              " 'I',\n",
              " 'can',\n",
              " 'no',\n",
              " 'long',\n",
              " 'assume',\n",
              " 'that',\n",
              " 'to',\n",
              " 'be',\n",
              " 'the',\n",
              " 'case',\n",
              " ' ',\n",
              " 'therefore',\n",
              " 'no',\n",
              " 'contradiction',\n",
              " ' ',\n",
              " 'matthew',\n",
              " 'do',\n",
              " 'not',\n",
              " 'say',\n",
              " 'judas',\n",
              " 'die',\n",
              " 'as',\n",
              " 'a',\n",
              " '                                          ',\n",
              " 'result',\n",
              " 'of',\n",
              " 'the',\n",
              " 'hanging',\n",
              " 'do',\n",
              " 'he',\n",
              " ' ',\n",
              " 'most',\n",
              " 'scholar',\n",
              " 'believe',\n",
              " 'he',\n",
              " 'iprobably',\n",
              " 'do',\n",
              " 'but',\n",
              " '  ',\n",
              " 'I',\n",
              " 'quote',\n",
              " 'all',\n",
              " 'that',\n",
              " 'to',\n",
              " 'show',\n",
              " 'that',\n",
              " 'I',\n",
              " 'highly',\n",
              " 'regard',\n",
              " 'the',\n",
              " 'scholar',\n",
              " 'explanation',\n",
              " 'but',\n",
              " 'in',\n",
              " 'look',\n",
              " 'at',\n",
              " 'the',\n",
              " 'text',\n",
              " 'initially',\n",
              " 'we',\n",
              " 'can',\n",
              " 'not',\n",
              " 'assume',\n",
              " 'judas',\n",
              " 'die',\n",
              " ' ',\n",
              " 'it',\n",
              " 'be',\n",
              " ' ',\n",
              " 'however',\n",
              " 'highly',\n",
              " 'probable',\n",
              " '                  ',\n",
              " 'and',\n",
              " ' ',\n",
              " 'also',\n",
              " 'there',\n",
              " 'be',\n",
              " 'nothing',\n",
              " 'in',\n",
              " 'the',\n",
              " 'greek',\n",
              " 'to',\n",
              " 'suggest',\n",
              " 'success',\n",
              " 'or',\n",
              " 'failure',\n",
              " ' ',\n",
              " 'it',\n",
              " 'simply',\n",
              " 'mean',\n",
              " 'hang',\n",
              " 'oneselfactually',\n",
              " 'if',\n",
              " 'you',\n",
              " 'do',\n",
              " 'further',\n",
              " 'research',\n",
              " 'as',\n",
              " 'to',\n",
              " 'the',\n",
              " 'greek',\n",
              " 'word',\n",
              " 'apacgw',\n",
              " 'you',\n",
              " 'willfind',\n",
              " 'that',\n",
              " 'it',\n",
              " 'do',\n",
              " 'denote',\n",
              " 'success',\n",
              " ' ',\n",
              " 'those',\n",
              " 'scholar',\n",
              " 'do',\n",
              " 'indeed',\n",
              " 'have',\n",
              " 'an',\n",
              " 'excellentreason',\n",
              " 'to',\n",
              " 'assume',\n",
              " 'that',\n",
              " 'the',\n",
              " 'suicide',\n",
              " 'be',\n",
              " 'successful',\n",
              " ' ',\n",
              " 'as',\n",
              " 'I',\n",
              " 'point',\n",
              " 'out',\n",
              " 'irecently',\n",
              " 'check',\n",
              " 'several',\n",
              " 'lexiconsgreek',\n",
              " 'english',\n",
              " 'lexicon',\n",
              " 'of',\n",
              " 'the',\n",
              " 'new',\n",
              " 'testament',\n",
              " 'louw',\n",
              " 'and',\n",
              " 'nidarobinson',\n",
              " 'greek',\n",
              " 'and',\n",
              " 'english',\n",
              " 'lexicon',\n",
              " 'of',\n",
              " 'the',\n",
              " 'new',\n",
              " 'testamentgreek',\n",
              " 'english',\n",
              " 'lexicon',\n",
              " 'of',\n",
              " 'the',\n",
              " 'new',\n",
              " 'testament',\n",
              " 'grimmword',\n",
              " 'study',\n",
              " 'concordance',\n",
              " 'tynsdalea',\n",
              " 'greek',\n",
              " 'english',\n",
              " 'lexicon',\n",
              " 'of',\n",
              " 'the',\n",
              " 'new',\n",
              " 'testament',\n",
              " 'and',\n",
              " 'other',\n",
              " ' ',\n",
              " 'early',\n",
              " 'christian',\n",
              " 'writing',\n",
              " 'bauerarndtgingrichthe',\n",
              " 'new',\n",
              " 'analytical',\n",
              " 'greek',\n",
              " 'lexicon',\n",
              " 'perschbachera',\n",
              " 'couple',\n",
              " 'simply',\n",
              " 'state',\n",
              " 'hang',\n",
              " 'oneself',\n",
              " 'and',\n",
              " 'a',\n",
              " 'couple',\n",
              " 'be',\n",
              " 'more',\n",
              " 'explicit',\n",
              " 'and',\n",
              " 'state',\n",
              " 'that',\n",
              " 'apacgw',\n",
              " 'mean',\n",
              " 'specifically',\n",
              " 'kill',\n",
              " 'yourself',\n",
              " 'by',\n",
              " 'hang',\n",
              " 'acouple',\n",
              " 'also',\n",
              " 'note',\n",
              " 'that',\n",
              " 'the',\n",
              " 'meaning',\n",
              " 'of',\n",
              " 'one',\n",
              " 'the',\n",
              " 'root',\n",
              " 'word',\n",
              " 'for',\n",
              " 'apacgw',\n",
              " 'isstrangle',\n",
              " 'throttle',\n",
              " 'or',\n",
              " 'choke',\n",
              " 'which',\n",
              " 'pretty',\n",
              " 'much',\n",
              " 'invalidate',\n",
              " 'the',\n",
              " 'guy',\n",
              " 'whosuggeste',\n",
              " 'to',\n",
              " 'david',\n",
              " 'joslin',\n",
              " 'that',\n",
              " 'judas',\n",
              " 'be',\n",
              " 'hang',\n",
              " 'upside',\n",
              " 'down',\n",
              " ' ',\n",
              " 'one',\n",
              " 'of',\n",
              " 'the',\n",
              " 'bestreference',\n",
              " 'though',\n",
              " 'robinson',\n",
              " 'greek',\n",
              " 'and',\n",
              " 'english',\n",
              " 'lexicon',\n",
              " 'of',\n",
              " 'the',\n",
              " 'newtestament',\n",
              " 'not',\n",
              " 'only',\n",
              " 'state',\n",
              " 'the',\n",
              " 'translation',\n",
              " 'it',\n",
              " 'give',\n",
              " 'both',\n",
              " 'the',\n",
              " 'root',\n",
              " 'word',\n",
              " 'theliteral',\n",
              " 'translation',\n",
              " 'relate',\n",
              " 'greek',\n",
              " 'word',\n",
              " 'which',\n",
              " 'use',\n",
              " 'the',\n",
              " 'same',\n",
              " 'root',\n",
              " 'and',\n",
              " 'alsoother',\n",
              " 'present',\n",
              " 'specific',\n",
              " 'example',\n",
              " 'of',\n",
              " 'the',\n",
              " 'word',\n",
              " 'in',\n",
              " 'greek',\n",
              " 'literature',\n",
              " 'to',\n",
              " 'givefurther',\n",
              " 'context',\n",
              " ' ',\n",
              " 'the',\n",
              " 'word',\n",
              " 'apagchw',\n",
              " 'have',\n",
              " 'two',\n",
              " 'root',\n",
              " 'word',\n",
              " 'gchw',\n",
              " 'be',\n",
              " 'the',\n",
              " 'to',\n",
              " 'strangle',\n",
              " 'root',\n",
              " 'andthe',\n",
              " 'root',\n",
              " 'word',\n",
              " 'apo',\n",
              " 'mean',\n",
              " 'literally',\n",
              " 'away',\n",
              " 'this',\n",
              " 'root',\n",
              " 'word',\n",
              " 'be',\n",
              " 'include',\n",
              " 'inword',\n",
              " 'which',\n",
              " 'denote',\n",
              " 'a',\n",
              " 'transition',\n",
              " ' ',\n",
              " 'it',\n",
              " 'can',\n",
              " 'mean',\n",
              " 'a',\n",
              " 'transition',\n",
              " 'in',\n",
              " 'place',\n",
              " 'eg',\n",
              " 'thegreek',\n",
              " 'word',\n",
              " 'apagello',\n",
              " 'mean',\n",
              " 'to',\n",
              " 'send',\n",
              " 'a',\n",
              " 'message',\n",
              " ' ',\n",
              " 'apo',\n",
              " 'can',\n",
              " 'also',\n",
              " 'denote',\n",
              " 'achange',\n",
              " 'in',\n",
              " 'state',\n",
              " 'and',\n",
              " 'specifically',\n",
              " 'the',\n",
              " 'change',\n",
              " 'from',\n",
              " 'life',\n",
              " 'to',\n",
              " 'death',\n",
              " ' ',\n",
              " 'robinsonspecifically',\n",
              " 'make',\n",
              " 'comparison',\n",
              " 'to',\n",
              " 'the',\n",
              " 'word',\n",
              " 'apokteiuo',\n",
              " 'which',\n",
              " 'mean',\n",
              " 'to',\n",
              " 'killin',\n",
              " 'literal',\n",
              " 'mean',\n",
              " 'the',\n",
              " 'word',\n",
              " 'apacgw',\n",
              " 'mean',\n",
              " 'to',\n",
              " 'throttle',\n",
              " 'strangle',\n",
              " 'to',\n",
              " 'put',\n",
              " 'outof',\n",
              " 'the',\n",
              " 'way',\n",
              " 'and',\n",
              " 'implicitly',\n",
              " 'denote',\n",
              " 'a',\n",
              " 'change',\n",
              " 'in',\n",
              " 'life',\n",
              " 'state',\n",
              " 'ie',\n",
              " 'away',\n",
              " 'fromlife',\n",
              " 'to',\n",
              " 'death',\n",
              " ' ',\n",
              " 'so',\n",
              " 'while',\n",
              " 'the',\n",
              " 'word',\n",
              " 'apacgw',\n",
              " 'do',\n",
              " 'mean',\n",
              " 'to',\n",
              " 'hang',\n",
              " 'itspecifically',\n",
              " 'denote',\n",
              " 'a',\n",
              " 'death',\n",
              " 'as',\n",
              " 'well',\n",
              " ' ',\n",
              " 'thus',\n",
              " 'robinson',\n",
              " 'be',\n",
              " 'quite',\n",
              " 'specific',\n",
              " 'when',\n",
              " 'hestate',\n",
              " 'that',\n",
              " 'it',\n",
              " 'mean',\n",
              " 'to',\n",
              " 'hang',\n",
              " 'oneself',\n",
              " 'to',\n",
              " 'end',\n",
              " 'one',\n",
              " 'life',\n",
              " 'by',\n",
              " 'hang',\n",
              " 'he',\n",
              " 'thennote',\n",
              " 'the',\n",
              " 'the',\n",
              " 'use',\n",
              " 'of',\n",
              " 'apacgw',\n",
              " 'in',\n",
              " 'homer',\n",
              " 'odessy',\n",
              " ' ',\n",
              " 'to',\n",
              " 'denote',\n",
              " 'context',\n",
              " ' ',\n",
              " 'hepresent',\n",
              " 'that',\n",
              " 'example',\n",
              " 'of',\n",
              " 'apacgw',\n",
              " 'as',\n",
              " 'be',\n",
              " 'use',\n",
              " 'to',\n",
              " 'explicitly',\n",
              " 'mean',\n",
              " 'suicide',\n",
              " 'byhanging',\n",
              " 'now',\n",
              " 'since',\n",
              " 'there',\n",
              " 'be',\n",
              " 'a',\n",
              " 'perfectly',\n",
              " 'good',\n",
              " 'word',\n",
              " 'for',\n",
              " 'strangle',\n",
              " 'without',\n",
              " 'theadde',\n",
              " 'denotation',\n",
              " 'of',\n",
              " 'death',\n",
              " 'and',\n",
              " 'as',\n",
              " 'you',\n",
              " 'insist',\n",
              " 'that',\n",
              " 'the',\n",
              " 'bible',\n",
              " 'be',\n",
              " 'write',\n",
              " 'bygod',\n",
              " 'and',\n",
              " 'every',\n",
              " 'word',\n",
              " 'be',\n",
              " 'precicely',\n",
              " 'correct',\n",
              " 'you',\n",
              " 'be',\n",
              " 'stick',\n",
              " 'with',\n",
              " 'the',\n",
              " 'completemeaning',\n",
              " 'of',\n",
              " 'apacgw',\n",
              " 'ie',\n",
              " 'since',\n",
              " 'the',\n",
              " 'word',\n",
              " 'apacgw',\n",
              " 'be',\n",
              " 'use',\n",
              " 'then',\n",
              " 'death',\n",
              " 'isdenote',\n",
              " 'as',\n",
              " 'the',\n",
              " 'result',\n",
              " 'by',\n",
              " 'the',\n",
              " 'way',\n",
              " 'I',\n",
              " 'note',\n",
              " 'that',\n",
              " 'mr',\n",
              " 'decenso',\n",
              " 'also',\n",
              " 'present',\n",
              " 'an',\n",
              " 'example',\n",
              " 'of',\n",
              " 'apacgw',\n",
              " 'in',\n",
              " 'the',\n",
              " 'septuagint',\n",
              " 'the',\n",
              " 'greek',\n",
              " 'translation',\n",
              " 'of',\n",
              " 'the',\n",
              " 'ot',\n",
              " 'use',\n",
              " 'at',\n",
              " 'the',\n",
              " 'time',\n",
              " 'of',\n",
              " 'jesus',\n",
              " 'its',\n",
              " 'only',\n",
              " 'use',\n",
              " 'in',\n",
              " ' ',\n",
              " 'samuel',\n",
              " '  ',\n",
              " 'now',\n",
              " 'when',\n",
              " 'ahithophel',\n",
              " 'see',\n",
              " 'that',\n",
              " 'his',\n",
              " 'advice',\n",
              " ' ',\n",
              " 'be',\n",
              " 'not',\n",
              " 'follow',\n",
              " 'he',\n",
              " 'saddle',\n",
              " 'a',\n",
              " 'donkey',\n",
              " 'and',\n",
              " 'arise',\n",
              " 'and',\n",
              " 'go',\n",
              " 'home',\n",
              " 'to',\n",
              " 'his',\n",
              " 'house',\n",
              " 'to',\n",
              " 'his',\n",
              " 'city',\n",
              " 'then',\n",
              " 'he',\n",
              " 'put',\n",
              " 'his',\n",
              " 'household',\n",
              " 'in',\n",
              " 'order',\n",
              " 'and',\n",
              " 'hang',\n",
              " 'himself',\n",
              " 'and',\n",
              " ' ',\n",
              " 'die',\n",
              " 'and',\n",
              " 'he',\n",
              " 'be',\n",
              " 'bury',\n",
              " 'in',\n",
              " 'his',\n",
              " 'father',\n",
              " 'tomb',\n",
              " '     ',\n",
              " 'notice',\n",
              " 'that',\n",
              " 'not',\n",
              " 'only',\n",
              " 'be',\n",
              " 'it',\n",
              " 'state',\n",
              " 'that',\n",
              " 'ahithophel',\n",
              " 'hang',\n",
              " 'himself',\n",
              " 'gr',\n",
              " 'sept',\n",
              " 'apagcho',\n",
              " 'but',\n",
              " 'it',\n",
              " 'explicitly',\n",
              " 'add',\n",
              " 'and',\n",
              " 'die',\n",
              " ' ',\n",
              " 'here',\n",
              " 'we',\n",
              " 'have',\n",
              " 'no',\n",
              " 'doubt',\n",
              " 'of',\n",
              " 'the',\n",
              " 'result',\n",
              " 'in',\n",
              " 'matthew',\n",
              " 'we',\n",
              " 'be',\n",
              " 'not',\n",
              " 'explicitly',\n",
              " 'tell',\n",
              " 'judas',\n",
              " 'diednote',\n",
              " 'mr',\n",
              " 'decenso',\n",
              " 'as',\n",
              " 'you',\n",
              " 'say',\n",
              " 'the',\n",
              " 'septuagint',\n",
              " 'be',\n",
              " 'a',\n",
              " 'translation',\n",
              " 'from',\n",
              " 'hebrew',\n",
              " 'togreek',\n",
              " 'and',\n",
              " 'you',\n",
              " 'have',\n",
              " 'not',\n",
              " 'show',\n",
              " 'the',\n",
              " 'original',\n",
              " 'meaning',\n",
              " 'of',\n",
              " 'the',\n",
              " 'hebrew',\n",
              " 'ie',\n",
              " 'the',\n",
              " 'thehebrew',\n",
              " 'say',\n",
              " 'and',\n",
              " 'die',\n",
              " 'and',\n",
              " 'thus',\n",
              " 'whether',\n",
              " 'it',\n",
              " 'be',\n",
              " 'simply',\n",
              " 'echo',\n",
              " 'in',\n",
              " 'the',\n",
              " 'greek',\n",
              " 'it',\n",
              " 'should',\n",
              " 'also',\n",
              " 'be',\n",
              " 'point',\n",
              " 'out',\n",
              " 'that',\n",
              " 'regardless',\n",
              " 'of',\n",
              " 'the',\n",
              " 'add',\n",
              " 'and',\n",
              " 'die',\n",
              " 'thecorrect',\n",
              " 'translation',\n",
              " 'would',\n",
              " 'still',\n",
              " 'be',\n",
              " 'apacgw',\n",
              " 'as',\n",
              " 'the',\n",
              " 'man',\n",
              " 'do',\n",
              " 'indeed',\n",
              " 'die',\n",
              " 'fromstrangulation',\n",
              " 'redundant',\n",
              " 'but',\n",
              " 'correct',\n",
              " ' ',\n",
              " 'far',\n",
              " 'we',\n",
              " 'have',\n",
              " 'evidence',\n",
              " 'that',\n",
              " 'theseptuagint',\n",
              " 'be',\n",
              " 'repeatedly',\n",
              " 'rewrite',\n",
              " 'and',\n",
              " 'reedite',\n",
              " 'which',\n",
              " 'include',\n",
              " 'versionswhich',\n",
              " 'contradict',\n",
              " 'each',\n",
              " 'other',\n",
              " 'and',\n",
              " 'such',\n",
              " 'editing',\n",
              " 'be',\n",
              " 'not',\n",
              " 'even',\n",
              " 'necessarilyexecute',\n",
              " 'by',\n",
              " 'greek',\n",
              " ' ',\n",
              " 'thus',\n",
              " 'I',\n",
              " 'be',\n",
              " 'not',\n",
              " 'sure',\n",
              " 'that',\n",
              " 'you',\n",
              " 'can',\n",
              " 'use',\n",
              " 'the',\n",
              " 'septuagint',\n",
              " 'as',\n",
              " 'itnow',\n",
              " 'stand',\n",
              " 'as',\n",
              " 'a',\n",
              " 'paragon',\n",
              " 'of',\n",
              " 'ancient',\n",
              " 'greek',\n",
              " ' ',\n",
              " 'so',\n",
              " 'what',\n",
              " 'you',\n",
              " 'really',\n",
              " 'need',\n",
              " 'to',\n",
              " 'proveyour',\n",
              " 'point',\n",
              " 'mr',\n",
              " 'decenso',\n",
              " 'be',\n",
              " 'an',\n",
              " 'example',\n",
              " 'in',\n",
              " 'ancient',\n",
              " 'greek',\n",
              " 'of',\n",
              " 'someone',\n",
              " 'committingapacgw',\n",
              " 'and',\n",
              " 'survive',\n",
              " ' ',\n",
              " 'otherwise',\n",
              " 'I',\n",
              " 'would',\n",
              " 'see',\n",
              " 'you',\n",
              " 'as',\n",
              " 'simply',\n",
              " 'make',\n",
              " 'worthlessassertion',\n",
              " 'without',\n",
              " 'correspond',\n",
              " 'evidence',\n",
              " 'now',\n",
              " 'I',\n",
              " 'would',\n",
              " 'note',\n",
              " 'mr',\n",
              " 'decenso',\n",
              " 'that',\n",
              " 'everytime',\n",
              " 'I',\n",
              " 'go',\n",
              " 'out',\n",
              " 'of',\n",
              " 'my',\n",
              " 'way',\n",
              " 'to',\n",
              " 'research',\n",
              " 'itone',\n",
              " 'of',\n",
              " 'your',\n",
              " 'apparently',\n",
              " 'contrive',\n",
              " 'exegisis',\n",
              " 'I',\n",
              " 'pretty',\n",
              " 'much',\n",
              " 'find',\n",
              " 'it',\n",
              " 'false',\n",
              " ' ',\n",
              " 'thusi',\n",
              " 'think',\n",
              " 'that',\n",
              " 'if',\n",
              " 'you',\n",
              " 'be',\n",
              " 'go',\n",
              " 'to',\n",
              " 'add',\n",
              " 'to',\n",
              " 'the',\n",
              " 'text',\n",
              " 'something',\n",
              " 'over',\n",
              " 'and',\n",
              " 'abovewhat',\n",
              " 'the',\n",
              " 'source',\n",
              " 'clearly',\n",
              " 'say',\n",
              " 'then',\n",
              " 'you',\n",
              " 'have',\n",
              " 'well',\n",
              " 'have',\n",
              " 'an',\n",
              " 'explicit',\n",
              " 'greek',\n",
              " 'orhistorical',\n",
              " 'source',\n",
              " 'to',\n",
              " 'justify',\n",
              " 'it',\n",
              " 'by',\n",
              " 'the',\n",
              " 'way',\n",
              " 'as',\n",
              " 'to',\n",
              " 'mr',\n",
              " 'rose',\n",
              " 'statement',\n",
              " 'about',\n",
              " 'tree',\n",
              " 'around',\n",
              " 'the',\n",
              " 'potter',\n",
              " 'field',\n",
              " 'there',\n",
              " 'be',\n",
              " 'still',\n",
              " 'tree',\n",
              " 'around',\n",
              " 'the',\n",
              " 'ledge',\n",
              " 'and',\n",
              " 'a',\n",
              " 'rocky',\n",
              " 'pavement',\n",
              " 'at',\n",
              " 'the',\n",
              " 'bottomunless',\n",
              " 'mr',\n",
              " 'rose',\n",
              " 'can',\n",
              " 'show',\n",
              " 'that',\n",
              " 'these',\n",
              " 'tree',\n",
              " 'be',\n",
              " 'two',\n",
              " 'thousand',\n",
              " 'year',\n",
              " 'old',\n",
              " 'or',\n",
              " 'thatthere',\n",
              " 'be',\n",
              " ' ',\n",
              " 'year',\n",
              " 'old',\n",
              " 'stump',\n",
              " 'there',\n",
              " 'or',\n",
              " 'have',\n",
              " 'a',\n",
              " ' ',\n",
              " 'thousand',\n",
              " 'year',\n",
              " 'old',\n",
              " 'descriptionof',\n",
              " 'the',\n",
              " 'area',\n",
              " 'which',\n",
              " 'mention',\n",
              " 'such',\n",
              " 'tree',\n",
              " 'then',\n",
              " 'it',\n",
              " 'be',\n",
              " 'inappropriate',\n",
              " 'for',\n",
              " 'he',\n",
              " 'toassert',\n",
              " 'that',\n",
              " 'the',\n",
              " 'present',\n",
              " 'placement',\n",
              " 'of',\n",
              " 'tree',\n",
              " 'prove',\n",
              " 'the',\n",
              " 'location',\n",
              " 'of',\n",
              " 'the',\n",
              " 'tree',\n",
              " 'twothousand',\n",
              " 'year',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сделаем список со всеми уникальными словами и создадим словарь, где каждому слову будет соответствовать его индекс."
      ],
      "metadata": {
        "id": "ERryfWESO2OS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wymukh0PC3vF",
        "outputId": "2bf17750-aa89-4147-d151-11246d820640"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52412"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "vocab = list(set(word for s in data for word in s))\n",
        "word_to_index = {word: i for i, word in enumerate(vocab)}\n",
        "len(vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Преобразуем все текста в векторы"
      ],
      "metadata": {
        "id": "YIk6GM1ZPTDV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HMmj1ciFlvx"
      },
      "outputs": [],
      "source": [
        "vData = []\n",
        "for s in data:\n",
        "    vector = [0] * len(vocab)\n",
        "    for word in s:\n",
        "        vector[word_to_index[word]] = 1\n",
        "    vData.append(vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JmLl5NQGAAe",
        "outputId": "0fe34a1a-b3d6-4aba-a374-b3ffc269da4e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2159"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "len(vData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Opv94CRLbmCn",
        "outputId": "55b58ae6-8f61-4105-e732-fd66640997a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([594, 595, 593, 377])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "np.bincount(newsgroups_train.target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBgsN4FJi9an"
      },
      "source": [
        "Дисбаланс классов наблюдается только в полседнем классе (не критичный)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучим модель"
      ],
      "metadata": {
        "id": "4TEarN9CPgBr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bRbglK9i9Mo"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yL86Eu3Qi9X_"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(vData, newsgroups_train.target,\n",
        "                                                    test_size=0.25,\n",
        "                                                    random_state=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-McMC5Dai9gP",
        "outputId": "e9afc453-6275-43fb-eb1a-21751daee724"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9296296296296296"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "model = SVC()\n",
        "model.fit(X_train, y_train)\n",
        "model.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Получили неплохой результат score (accuracy)"
      ],
      "metadata": {
        "id": "IlCQ-ijbPmO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = model.predict(X_test)"
      ],
      "metadata": {
        "id": "AI1BbKjPINYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPZbfeUkK2OQ",
        "outputId": "d11e66a1-2b1b-4ccc-d450-72e60a19b352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[137,   1,   7,   2],\n",
              "       [  6, 137,   8,   0],\n",
              "       [  3,   0, 151,   0],\n",
              "       [  3,   1,   7,  77]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Хороший результат, мы видим, что на главной диагонали высокие значения, модель ошиблась больше всего во втором классе. Самый лучший класс - 3, всего 3 ошибки из 154 вариантов"
      ],
      "metadata": {
        "id": "5QMBKgtQUqTD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_K8NLmDVds1",
        "outputId": "5b21d163-3d87-436e-f88a-fba8c6f09172"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5259259259259259"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "model = KNeighborsClassifier(n_neighbors=3)\n",
        "model.fit(X_train, y_train)\n",
        "model.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = model.predict(X_test)\n",
        "confusion_matrix(y_test, predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_wwMWMtQmrH",
        "outputId": "e59a6e31-c1c4-423a-8340-12e41567264f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[147,   0,   0,   0],\n",
              "       [ 98,  52,   1,   0],\n",
              "       [101,   1,  52,   0],\n",
              "       [ 55,   0,   0,  33]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель показала плохие результаты, она начала выдавать с большей вероятностью первый класс, поэтому первый класс безошибочный, а остальные - плохие."
      ],
      "metadata": {
        "id": "kFWCsXUuV0lP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "model.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YN475mwTOIR",
        "outputId": "100bb894-58e5-4c67-cd04-123f12790dd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8629629629629629"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = model.predict(X_test)\n",
        "confusion_matrix(y_test, predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgf8BPuvUI7d",
        "outputId": "72e9b956-bd7b-4d5c-802d-0b04d3c7605b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[132,   3,   7,   5],\n",
              "       [  8, 133,   8,   2],\n",
              "       [  9,   5, 134,   6],\n",
              "       [  8,   6,   7,  67]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Результаты неплохие, но хуже чем у SVC, ошибок примерно одинаково во всех классах, но больше всего в минорном 4 классе."
      ],
      "metadata": {
        "id": "Ge9OnnswXrVJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вывод: лучший результат показала SVC - 93%, следовательно она подхожит лучше для задачи классификации на этом наборе данных. (Возможно если сбалансировать классы, то DecisionTree поборолся бы с ним за первое место)"
      ],
      "metadata": {
        "id": "VWJyGzJOYNVV"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {
        "height": "11.8333px",
        "width": "160px"
      },
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "339.717px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}