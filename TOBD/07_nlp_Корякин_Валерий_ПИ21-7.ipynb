{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в обработку текста на естественном языке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Автор задач: Блохин Н.В. (NVBlokhin@fa.ru)__\n",
    "\n",
    "Материалы:\n",
    "* Макрушин С.В. Лекция \"Введение в обработку текста на естественном языке\"\n",
    "* https://www.nltk.org/api/nltk.metrics.distance.html\n",
    "* https://pymorphy2.readthedocs.io/en/stable/user/guide.html\n",
    "* https://realpython.com/nltk-nlp-python/\n",
    "* https://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy2 in c:\\users\\user\\pycharmprojects\\mak3\\venv\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\user\\pycharmprojects\\mak3\\venv\\lib\\site-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\user\\pycharmprojects\\mak3\\venv\\lib\\site-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\user\\pycharmprojects\\mak3\\venv\\lib\\site-packages (from pymorphy2) (0.6.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user\\pycharmprojects\\mak3\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user\\pycharmprojects\\mak3\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user\\pycharmprojects\\mak3\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user\\pycharmprojects\\mak3\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user\\pycharmprojects\\mak3\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user\\pycharmprojects\\mak3\\venv\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.1.2; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\User\\PycharmProjects\\mak3\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Загрузите данные из файла `ru_recipes_sample.csv` в виде `pd.DataFrame` `recipes` Используя регулярные выражения, удалите из описаний (столбец `description`) все символы, кроме русских букв, цифр и пробелов. Приведите все слова в описании к нижнему регистру. Сохраните полученный результат в столбец `description`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "0       Этот коктейль готовлю из замороженной клубники...\n1                                         Быстро и вкусно\n2                Сытный овощной салатик пальчики оближете\n3       Картофельное пюре и куриные котлеты  вкусная к...\n4       Вишневая наливка имеет яркий вишневый вкус кот...\n                              ...                        \n3462    Для тех кто любит чечевицу Вам сюда Очень вкус...\n3463    Баклажановые фантазии продолжаются Предлагаю В...\n3464    Мое любимое блюдо лазанья Но кушать только фар...\n3465    Прошлым летом варила варенье из одуванчиков по...\n3466     И три корочки хлеба  сделал заказ Буратино в ...\nName: description, Length: 3467, dtype: object"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "ruRecipesSample = pd.read_csv(\"ru_recipes_sample.csv\")\n",
    "r = re.compile(r\"[^a-яA-я 1-9]*\")\n",
    "ruRecipesSample['description'] = ruRecipesSample['description'].apply(lambda a: re.sub(r, \"\", a))\n",
    "ruRecipesSample['description']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расстояние редактирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Получите набор уникальных слов `words`, содержащихся в текстах описаний рецептов (воспользуйтесь `word_tokenize` из `nltk`). Сгенерируйте 5 пар случайно выбранных слов и посчитайте между ними расстояние Левенштейна. Выведите на экран результат в следующем виде:\n",
    "\n",
    "```\n",
    "d(word1, word2) = x\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d(кедровых, Шарики) = 7\n",
      "d(модифицировала, Чудесный) = 13\n",
      "d(каждодневного, покушать) = 12\n",
      "d(гарнирыв, свечe) = 8\n",
      "d(весне, веке) = 2\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "words = set()\n",
    "for i in ruRecipesSample[\"description\"]:\n",
    "    for j in word_tokenize(i):\n",
    "        words.add(j)\n",
    "words = list(words)\n",
    "for i in range(5):\n",
    "    word1 = random.choice(words)\n",
    "    word2 = random.choice(words)\n",
    "    print(f\"d({word1}, {word2}) = {nltk.edit_distance(word1, word2)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Напишите функцию, которая принимает на вход 2 текстовые строки `s1` и `s2` и при помощи расстояния Левенштейна определяет, является ли строка `s2` плагиатом `s1`. Функция должна реализовывать следующую логику: для каждого слова `w1` из `s1` проверяет, есть в `s2` хотя бы одно слово `w2`, такое, что расстояние Левенштейна между `w1` и `w2` меньше 2, и считает количество таких слов в `s1` $P$.\n",
    "\n",
    "$$ P = \\#\\{w_1 \\in s_1\\ | \\exists w_2 \\in s_2 : d(w_1, w_2) < tol\\}$$\n",
    "\n",
    "$$ L = max(|s1|, |s2|) $$\n",
    "\n",
    "Здесь $|\\cdot|$ - количество слов в строке, $\\#A$ - число элементов в множестве $A$, $w \\in s$ означает, что слово $w$ содержится в тексте $s$.\n",
    "\n",
    "Если отношение $P / L$ больше 0.8, то функция должна вернуть True; иначе False.\n",
    "\n",
    "Продемонстрируйте работу вашей функции на примере описаний двух рецептов с ID 135488 и 851934 (ID рецепта - это число, стоящее в конце url рецепта). Выведите на экран описания этих рецептов и результат работы функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_plagiarism(s1: str, s2: str) -> bool:\n",
    "    words1 = word_tokenize(s1)\n",
    "    words2 = word_tokenize(s2)\n",
    "    p = 0\n",
    "    l = max(len(words1), len(words2))\n",
    "    for i in words2:\n",
    "        for j in words1:\n",
    "            if nltk.edit_distance(i, j) < 2:\n",
    "                p +=1\n",
    "                break\n",
    "    return True if p/l > 0.8 else False\n",
    "\n",
    "data3 = ruRecipesSample.where(ruRecipesSample['url'].apply(lambda a: a.split(\"/\")[-2] in ['135488', '851934'])).dropna()\n",
    "is_plagiarism(data3.iloc[0]['description'], data3.iloc[1]['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стемминг, лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. На основе набора слов из задания 2 создайте `pd.DataFrame` со столбцами `word`, `stemmed_word` и `normalized_word`. В столбец `stemmed_word` поместите версию слова после проведения процедуры стемминга; в столбец `normalized_word` поместите версию слова после проведения процедуры лемматизации. Столбец `word` укажите в качестве индекса. \n",
    "\n",
    "Для стемминга можно воспользоваться `SnowballStemmer` из `nltk`, для лемматизации слов - пакетом `pymorphy2`. Сравните результаты стемминга и лемматизации. Поясните на примере одной из строк получившегося фрейма (в виде текстового комментария), в чем разница между двумя этими подходами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "                stemmed_word normalized_word\nwords                                       \nужин                    ужин            ужин\nприсутствовала  присутствова  присутствовать\nлепту                   лепт           лепта\nБелебеевский      белебеевск    белебеевский\nцелом                    цел           целое\n...                      ...             ...\nИталию                  итал          италия\nпалочке               палочк         палочка\nтреской                треск          треска\nпьяной                  пьян          пьяный\nжар                      жар             жар\n\n[19044 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stemmed_word</th>\n      <th>normalized_word</th>\n    </tr>\n    <tr>\n      <th>words</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ужин</th>\n      <td>ужин</td>\n      <td>ужин</td>\n    </tr>\n    <tr>\n      <th>присутствовала</th>\n      <td>присутствова</td>\n      <td>присутствовать</td>\n    </tr>\n    <tr>\n      <th>лепту</th>\n      <td>лепт</td>\n      <td>лепта</td>\n    </tr>\n    <tr>\n      <th>Белебеевский</th>\n      <td>белебеевск</td>\n      <td>белебеевский</td>\n    </tr>\n    <tr>\n      <th>целом</th>\n      <td>цел</td>\n      <td>целое</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Италию</th>\n      <td>итал</td>\n      <td>италия</td>\n    </tr>\n    <tr>\n      <th>палочке</th>\n      <td>палочк</td>\n      <td>палочка</td>\n    </tr>\n    <tr>\n      <th>треской</th>\n      <td>треск</td>\n      <td>треска</td>\n    </tr>\n    <tr>\n      <th>пьяной</th>\n      <td>пьян</td>\n      <td>пьяный</td>\n    </tr>\n    <tr>\n      <th>жар</th>\n      <td>жар</td>\n      <td>жар</td>\n    </tr>\n  </tbody>\n</table>\n<p>19044 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "snb_stemmer_ru = SnowballStemmer('russian')\n",
    "wordsDf = pd.DataFrame(words, columns=['words'])\n",
    "wordsDf['stemmed_word'] = wordsDf[\"words\"].apply(lambda a: snb_stemmer_ru.stem(a))\n",
    "wordsDf['normalized_word'] = wordsDf[\"words\"].apply(lambda a: morph.normal_forms(a)[0])\n",
    "wordsDf.index = wordsDf[\"words\"]\n",
    "wordsDf.drop(columns=[\"words\"], inplace=True)\n",
    "wordsDf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Добавьте в таблицу `recipes` столбец `description_no_stopwords`, в котором содержится текст описания рецепта после удаления из него стоп-слов. Посчитайте и выведите на экран долю стоп-слов среди общего количества слов. Сравните топ-10 самых часто употребляемых слов до и после удаления стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процент стоп слов: 32.03700830165257\n",
      "[('и', 5043), ('в', 2566), ('с', 1930), ('на', 1642), ('очень', 1594), ('не', 1517), ('из', 1005), ('я', 972), ('а', 849), ('рецепт', 843)]\n",
      "[('очень', 1594), ('рецепт', 843), ('это', 728), ('блюдо', 521), ('вкусный', 459), ('просто', 434), ('вкусно', 366), ('приготовить', 342), ('вкус', 318), ('салат', 312)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from razdel import tokenize\n",
    "\n",
    "cws = 0\n",
    "cw = 0\n",
    "def pop_stop_words(st):\n",
    "    wrds = word_tokenize(st)\n",
    "    retWrds = []\n",
    "    for i in wrds:\n",
    "        if i.lower() not in ru_stop_words:\n",
    "            retWrds.append(i)\n",
    "    return ' '.join(retWrds)\n",
    "\n",
    "ru_stop_words = stopwords.words(\"russian\")\n",
    "ruRecipesSample[\"description_no_stopwords\"] = ruRecipesSample[\"description\"].apply(lambda a: pop_stop_words(a))\n",
    "count_words = sum(ruRecipesSample[\"description\"].apply(lambda a: len(word_tokenize(a))))\n",
    "count_no_stopwords = sum(ruRecipesSample[\"description_no_stopwords\"].apply(lambda a: len(word_tokenize(a))))\n",
    "print(f'Процент стоп слов: {(count_words - count_no_stopwords)/count_words* 100}')\n",
    "\n",
    "words5 = \"\"\n",
    "for i in ruRecipesSample[\"description\"]:\n",
    "    words5 += i.lower() + \" \"\n",
    "words5_2 = \"\"\n",
    "for i in ruRecipesSample[\"description_no_stopwords\"]:\n",
    "    words5_2 += i.lower() + \" \"\n",
    "print(FreqDist(word_tokenize(words5)).most_common(10))\n",
    "print(FreqDist(word_tokenize(words5_2)).most_common(10))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ### Векторное представление текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Выберите случайным образом 5 рецептов из набора данных, в названии которых есть слово \"оладьи\" (без учета регистра). Представьте описание каждого рецепта в виде числового вектора при помощи `TfidfVectorizer`. На основе полученных векторов создайте `pd.DataFrame`, в котором названия колонок соответствуют словам из словаря объекта-векторизатора. \n",
    "\n",
    "Примечание: обратите внимание на порядок слов при создании колонок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "        2мл   близких     блины     блюдо  брокколи       был  бюджетное  \\\n0  0.136826  0.000000  0.000000  0.000000  0.000000  0.110391   0.000000   \n1  0.000000  0.306413  0.000000  0.000000  0.000000  0.000000   0.000000   \n2  0.000000  0.000000  0.192788  0.000000  0.000000  0.155540   0.000000   \n3  0.000000  0.000000  0.000000  0.306413  0.000000  0.000000   0.306413   \n4  0.000000  0.000000  0.000000  0.000000  0.259428  0.000000   0.000000   \n\n      везде      вкус    вкусно  ...    урожай     фарша   хороший    хорошо  \\\n0  0.136826  0.110391  0.000000  ...  0.136826  0.136826  0.136826  0.136826   \n1  0.000000  0.247212  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n2  0.000000  0.000000  0.155540  ...  0.000000  0.000000  0.000000  0.000000   \n3  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n4  0.000000  0.000000  0.209305  ...  0.000000  0.000000  0.000000  0.000000   \n\n   цитрусом       что     шалот       это      этом      этот  \n0  0.000000  0.110391  0.136826  0.000000  0.136826  0.000000  \n1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n2  0.192788  0.155540  0.000000  0.385576  0.000000  0.192788  \n3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n\n[5 rows x 92 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>2мл</th>\n      <th>близких</th>\n      <th>блины</th>\n      <th>блюдо</th>\n      <th>брокколи</th>\n      <th>был</th>\n      <th>бюджетное</th>\n      <th>везде</th>\n      <th>вкус</th>\n      <th>вкусно</th>\n      <th>...</th>\n      <th>урожай</th>\n      <th>фарша</th>\n      <th>хороший</th>\n      <th>хорошо</th>\n      <th>цитрусом</th>\n      <th>что</th>\n      <th>шалот</th>\n      <th>это</th>\n      <th>этом</th>\n      <th>этот</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.136826</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.110391</td>\n      <td>0.000000</td>\n      <td>0.136826</td>\n      <td>0.110391</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.136826</td>\n      <td>0.136826</td>\n      <td>0.136826</td>\n      <td>0.136826</td>\n      <td>0.000000</td>\n      <td>0.110391</td>\n      <td>0.136826</td>\n      <td>0.000000</td>\n      <td>0.136826</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.306413</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.247212</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.192788</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.155540</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.155540</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.192788</td>\n      <td>0.155540</td>\n      <td>0.000000</td>\n      <td>0.385576</td>\n      <td>0.000000</td>\n      <td>0.192788</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.306413</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.306413</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.259428</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.209305</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 92 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "c = 0\n",
    "data6 = []\n",
    "for i in range(ruRecipesSample[\"name\"].size):\n",
    "    if \"оладьи\" in ruRecipesSample[\"name\"][i].lower():\n",
    "        data6.append(ruRecipesSample[\"description\"][i])\n",
    "        c += 1\n",
    "        if c== 5:\n",
    "            break\n",
    "\n",
    "tv = TfidfVectorizer()\n",
    "corpus_tv = tv.fit_transform(data6)\n",
    "df6 = pd.DataFrame(corpus_tv.toarray(), columns=tv.get_feature_names_out())\n",
    "df6"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
